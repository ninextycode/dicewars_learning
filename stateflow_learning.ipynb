{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf2cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib ipympl\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from torch import nn\n",
    "import networkx as nx\n",
    "from torch.utils.data import DataLoader, ConcatDataset, random_split\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import time\n",
    "import csv\n",
    "from learning.model.stateflow import DWStateFlowModel\n",
    "from learning.data.stateflow_dataset import DWStateFlowDataset\n",
    "from learning.data.stateflow_utils import collate_stateflow_data\n",
    "from learning.data.av_utils import move_to_device\n",
    "from learning.data.stateflow_utils import (\n",
    "    extract_input, \n",
    "    extract_winners_output_target, \n",
    "    extract_action_output_target\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ec62fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef655bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_folder = \"server/history/\"\n",
    "history_files = sorted(glob.glob(os.path.join(history_folder, \"history_*.json\")))\n",
    "\n",
    "datasets = [DWStateFlowDataset(f) for f in history_files]\n",
    "concatenated_dataset = ConcatDataset(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01bb016e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183374\n"
     ]
    }
   ],
   "source": [
    "print(len(concatenated_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a491680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using seed: 6821409\n",
      "train_ds 146700\n",
      "val_ds 18337\n",
      "test_ds 18337\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "seed = random.randint(1, 10000000)\n",
    "print(f\"Using seed: {seed}\")\n",
    "\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "\n",
    "train_ds, val_ds, test_ds = random_split(\n",
    "    concatenated_dataset,\n",
    "    [0.8, 0.1, 0.1],\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_ds, 20000, pin_memory=True, shuffle=True, \n",
    "                         collate_fn=collate_stateflow_data, generator=generator)\n",
    "val_loader = DataLoader(val_ds, 20000, pin_memory=True, shuffle=True, \n",
    "                       collate_fn=collate_stateflow_data, generator=generator)\n",
    "\n",
    "print(\"train_ds\", len(train_ds))\n",
    "print(\"val_ds\", len(val_ds))\n",
    "print(\"test_ds\", len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8279e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e908f5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading latest checkpoint: learning/stateflow_checkpoints/stateflow_260.pt (epoch 260)\n"
     ]
    }
   ],
   "source": [
    "model_state = None\n",
    "scheduler_state = None\n",
    "combined_criterion_state = None\n",
    "latest_epoch = -1\n",
    "\n",
    "models_dir = \"learning/stateflow_checkpoints\" \n",
    "model_name = \"stateflow\"\n",
    "\n",
    "# Find the latest checkpoint file (with highest epoch number)\n",
    "checkpoint_files = glob.glob(os.path.join(models_dir, f\"{model_name}_*.pt\"))\n",
    "if checkpoint_files:\n",
    "    # Extract epoch numbers from filenames\n",
    "    epoch_nums = [int(f.split(\"_\")[-1].split(\".\")[0]) for f in checkpoint_files]\n",
    "    latest_epoch = max(epoch_nums)\n",
    "    latest_checkpoint = os.path.join(models_dir, f\"{model_name}_{latest_epoch}.pt\")\n",
    "    print(f\"Loading latest checkpoint: {latest_checkpoint} (epoch {latest_epoch})\")\n",
    "    checkpoint = torch.load(latest_checkpoint)\n",
    "    model_state = checkpoint[\"model_state\"]\n",
    "    combined_criterion_state = checkpoint[\"combined_criterion_state\"]\n",
    "    scheduler_state = checkpoint[\"scheduler_state\"]\n",
    "else:\n",
    "    print(\"No valid checkpoint files found\")\n",
    "\n",
    "start_epoch = latest_epoch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03aaa13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f341c2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWStateFlowModel(\n",
      "  (norm_fn): DWNorm()\n",
      "  (gat_layers): ModuleList(\n",
      "    (0): GATLayer(\n",
      "      (message_fn): GATMessage(\n",
      "        (input_dropout): Dropout(p=0, inplace=False)\n",
      "        (transform_fn): Linear(in_features=8, out_features=8, bias=False)\n",
      "      )\n",
      "      (attention_coef_fn): GATAttentionCoefficients(\n",
      "        (transform_fn): Linear(in_features=16, out_features=1, bias=False)\n",
      "        (activation_fn): LeakyReLU(negative_slope=0.01)\n",
      "      )\n",
      "      (attention_dropout): Dropout(p=0.35, inplace=False)\n",
      "      (activation_fn): ReLU()\n",
      "      (residual_proj): Linear(in_features=8, out_features=8, bias=False)\n",
      "      (residual_dropout): Dropout(p=0.35, inplace=False)\n",
      "    )\n",
      "    (1-2): 2 x GATLayer(\n",
      "      (message_fn): GATMessage(\n",
      "        (input_dropout): Dropout(p=0.35, inplace=False)\n",
      "        (transform_fn): Linear(in_features=8, out_features=8, bias=False)\n",
      "      )\n",
      "      (attention_coef_fn): GATAttentionCoefficients(\n",
      "        (transform_fn): Linear(in_features=16, out_features=1, bias=False)\n",
      "        (activation_fn): LeakyReLU(negative_slope=0.01)\n",
      "      )\n",
      "      (attention_dropout): Dropout(p=0.35, inplace=False)\n",
      "      (activation_fn): ReLU()\n",
      "      (residual_proj): Linear(in_features=8, out_features=8, bias=False)\n",
      "      (residual_dropout): Dropout(p=0.35, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (winner_logit_fn): GATGraphSummary(\n",
      "    (input_dropout): Dropout(p=0.35, inplace=False)\n",
      "    (attention_coef_fn): GATAttentionCoefficients(\n",
      "      (transform_fn): Linear(in_features=8, out_features=1, bias=False)\n",
      "      (activation_fn): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (attention_dropout): Dropout(p=0.2, inplace=False)\n",
      "    (summary_fn): Linear(in_features=8, out_features=8, bias=True)\n",
      "  )\n",
      "  (attack_logit_fn): GATEdgeValue(\n",
      "    (edge_value_fn): Linear(in_features=16, out_features=1, bias=True)\n",
      "    (edge_state_dropout): Dropout(p=0.35, inplace=False)\n",
      "  )\n",
      "  (end_turn_logit_fn): GATGraphSummary(\n",
      "    (input_dropout): Dropout(p=0.35, inplace=False)\n",
      "    (attention_coef_fn): GATAttentionCoefficients(\n",
      "      (transform_fn): Linear(in_features=8, out_features=1, bias=False)\n",
      "      (activation_fn): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (attention_dropout): Dropout(p=0.2, inplace=False)\n",
      "    (summary_fn): Linear(in_features=8, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Total trainable parameters: 357\n"
     ]
    }
   ],
   "source": [
    "stateflow_model = DWStateFlowModel()\n",
    "print(stateflow_model)\n",
    "num_params = sum(p.numel() for p in stateflow_model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {num_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93b7ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57bb58b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateflowLoss(nn.Module):\n",
    "    # homoscedastic uncertainty trick implementation\n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "        self.winner_err_log_scale = nn.Parameter(torch.tensor(0, dtype=torch.float32))\n",
    "        self.action_err_log_scale = nn.Parameter(torch.tensor(0, dtype=torch.float32))\n",
    "    \n",
    "    def forward(self, winner_change_err, action_logit_error):\n",
    "        winner_err_rescaled = \\\n",
    "            winner_change_err * torch.exp(-self.winner_err_log_scale) + self.winner_err_log_scale\n",
    "        action_err_rescaled = \\\n",
    "            action_logit_error * torch.exp(-self.action_err_log_scale) + self.action_err_log_scale\n",
    "        \n",
    "        return winner_err_rescaled + action_err_rescaled\n",
    "    \n",
    "\n",
    "class MSELossWithOverflow:\n",
    "    # add an error for output whose absolute value is greater than abs_max\n",
    "    def __init__(self, abs_max, overflow_scale = 0.15):\n",
    "        self.abs_max = abs_max\n",
    "        self.mse_crit = nn.MSELoss()\n",
    "        self.overflow_crit = nn.MSELoss()\n",
    "        self.overflow_scale = overflow_scale\n",
    "\n",
    "    def __call__(self, output, target):\n",
    "        loss = self.mse_crit(output, target)\n",
    "        overflow = torch.relu(torch.abs(output) - self.abs_max)\n",
    "        overflow_loss = torch.mean(overflow ** 2)  # MSE\n",
    "        return loss + self.overflow_scale * overflow_loss\n",
    "    \n",
    "\n",
    "# end_turn_flags = torch.tensor([d[\"attack_edge\"][0] == -1 for d in concatenated_dataset])\n",
    "# p_end_turn = torch.mean(1.0 * end_turn_flags)\n",
    "# p_attack = 1 - p_end_turn\n",
    "# print(p_end_turn, p_attack)  # tensor(0.2190) tensor(0.7810)\n",
    "p_end_turn, p_attack = 0.25, 0.75\n",
    "\n",
    "class IterativeCrossEntropyLoss:\n",
    "    def __init__(self):\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def get_weights(self, o_logits):     \n",
    "        n_actions = o_logits.shape[-1]       \n",
    "        weights = torch.ones(n_actions, device=o_logits.device, dtype=o_logits.dtype)\n",
    "        weights[-1] = 1 / p_end_turn  # end turn action\n",
    "        p_single_edge = (1 - p_end_turn) / n_actions\n",
    "        weights[:-1] = 1 / p_single_edge  # attack along edge action  \n",
    "        weights = n_actions * (weights / weights.sum())  # maintain unweighted pytorch loss scale\n",
    "        return weights\n",
    "\n",
    "    def __call__(self, output, target):\n",
    "        losses = []\n",
    "        for o_logits, t_classes in zip(output, target):\n",
    "            weights = self.get_weights(o_logits)\n",
    "            loss = nn.functional.cross_entropy(o_logits, t_classes, weight=weights)\n",
    "            losses.append(loss)\n",
    "        return torch.mean(torch.stack(losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8035e81d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8fe35be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model before everything else so that I can freeze some layers\n",
    "if model_state is not None:\n",
    "    stateflow_model.load_state_dict(model_state)\n",
    "\n",
    "stateflow_model.gat_layers[0].requires_grad_(False)\n",
    "stateflow_model.gat_layers[1].reset_parameters()\n",
    "stateflow_model.gat_layers[2].reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c870636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── CSV set‑up: log one row per epoch ───────────────────────────────────────\n",
    "csv_path = \"stateflow_epoch_metrics.csv\"\n",
    "epoch_log_file_exists = os.path.isfile(csv_path)\n",
    "if epoch_log_file_exists and os.path.getsize(csv_path) == 0:\n",
    "    os.remove(csv_path)\n",
    "    epoch_log_file_exists = False\n",
    "\n",
    "csv_file = open(csv_path, \"a\", newline=\"\")  # Open in append mode\n",
    "csv_writer = csv.writer(csv_file)\n",
    "\n",
    "csv_header = [\n",
    "    \"epoch\",              # 0‑based epoch index\n",
    "    \"train_winner_loss\",   # average winner prediction training loss for the epoch\n",
    "    \"train_action_loss\",  # average action prediction training loss for the epoch\n",
    "    \"train_combined_loss\", # average combined training loss for the epoch\n",
    "    \"val_winner_loss\",     # average winner validation loss for the epoch\n",
    "    \"val_action_loss\",    # average action validation loss for the epoch\n",
    "    \"val_combined_loss\",  # average combined validation loss for the epoch\n",
    "    \"train_time_sec\",     # seconds spent in training phase\n",
    "    \"val_time_sec\",       # seconds spent in validation phase\n",
    "    \"total_time_sec\",     # train + val\n",
    "    \"winner_err_log_scale\", # winner error log scale parameter\n",
    "    \"action_err_log_scale\" # action error log scale parameter\n",
    "]\n",
    "\n",
    "# ── model / optimizer prep ─────────────────────────────────────────────────\n",
    "\n",
    "n_epochs   = 1000\n",
    "device     = torch.device(\"cuda\", 0)\n",
    "time_limit = 10 * 60\n",
    "winner_criterion = nn.CrossEntropyLoss()\n",
    "action_criterion = IterativeCrossEntropyLoss()\n",
    "combined_criterion = StateflowLoss()\n",
    "\n",
    "if combined_criterion_state is not None:\n",
    "    combined_criterion.load_state_dict(combined_criterion_state)\n",
    "\n",
    "# Update optimizer to include both model and loss function parameters\n",
    "model_optimizer = torch.optim.Adam([p for p in stateflow_model.parameters() if p.requires_grad], lr=9e-2)\n",
    "combined_criterion_optimizer = torch.optim.SGD(combined_criterion.parameters(), lr=1e-2)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(model_optimizer, step_size=20, gamma=0.9)\n",
    "\n",
    "reset_scheduler = False\n",
    "if not reset_scheduler and scheduler_state is not None:\n",
    "    scheduler.load_state_dict(scheduler_state)\n",
    "else:\n",
    "    # If no scheduler state in checkpoint, step it to match the epoch\n",
    "    print(f\"No scheduler state found in checkpoint, stepping scheduler to epoch {start_epoch}\")\n",
    "    for _ in range(start_epoch):\n",
    "        scheduler.step()\n",
    "\n",
    "stateflow_model = stateflow_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b987bfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(stateflow_model, batch):\n",
    "    batch = move_to_device(batch, device)\n",
    "    model_out = stateflow_model(*extract_input(batch))\n",
    "\n",
    "    winner_output, winner_target = \\\n",
    "        extract_winners_output_target(batch, model_out)\n",
    "    action_output, action_target = \\\n",
    "        extract_action_output_target(batch, model_out)\n",
    "\n",
    "    winner_loss = winner_criterion(winner_output, winner_target)\n",
    "    action_loss = action_criterion(action_output, action_target)\n",
    "    combined_loss = combined_criterion.forward(winner_loss, action_loss)\n",
    "    return winner_loss, action_loss, combined_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e89830c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── INITIAL (untrained) LOSS EVALUATION ───────────────────────────────────────\n",
    "if not epoch_log_file_exists:\n",
    "    stateflow_model.eval()\n",
    "    with torch.no_grad():\n",
    "        t_start = time.time()\n",
    "\n",
    "        # avg loss on training set *without* gradient tracking\n",
    "        init_train_winner_sum = torch.tensor(0.0, device=device)\n",
    "        init_train_action_sum = torch.tensor(0.0, device=device)\n",
    "        init_train_combined_sum = torch.tensor(0.0, device=device)\n",
    "        init_train_batches = 0\n",
    "        \n",
    "        for tb in tqdm.tqdm(train_loader, desc=\"init-train\"):\n",
    "            winner_loss, action_loss, combined_loss = process_batch(stateflow_model, tb)\n",
    "            \n",
    "            init_train_winner_sum += winner_loss\n",
    "            init_train_action_sum += action_loss\n",
    "            init_train_combined_sum += combined_loss\n",
    "            init_train_batches += 1\n",
    "            \n",
    "            if (time.time() - t_start) > time_limit: \n",
    "                print(f\"Stopping initial training evaluation after >{time_limit} seconds.\")\n",
    "                break\n",
    "                \n",
    "        init_train_winner_loss = init_train_winner_sum.item() / init_train_batches\n",
    "        init_train_action_loss = init_train_action_sum.item() / init_train_batches\n",
    "        init_train_combined_loss = init_train_combined_sum.item() / init_train_batches\n",
    "        t_train_done = time.time()\n",
    "\n",
    "        # avg loss on validation set\n",
    "        init_val_winner_sum = torch.tensor(0.0, device=device)\n",
    "        init_val_action_sum = torch.tensor(0.0, device=device)\n",
    "        init_val_combined_sum = torch.tensor(0.0, device=device)\n",
    "        init_val_batches = 0\n",
    "        \n",
    "        for vb in tqdm.tqdm(val_loader, desc=\"init-val\"):\n",
    "            v_winner_loss, v_action_loss, v_combined_loss = process_batch(stateflow_model, vb)\n",
    "            \n",
    "            init_val_winner_sum += v_winner_loss\n",
    "            init_val_action_sum += v_action_loss\n",
    "            init_val_combined_sum += v_combined_loss\n",
    "            init_val_batches += 1\n",
    "            \n",
    "            if (time.time() - t_train_done) > time_limit / 5:\n",
    "                print(f\"Stopping initial validation evaluation after >{time_limit / 5} seconds.\")\n",
    "                break\n",
    "                \n",
    "        init_val_winner_loss = init_val_winner_sum.item() / init_val_batches\n",
    "        init_val_action_loss = init_val_action_sum.item() / init_val_batches\n",
    "        init_val_combined_loss = init_val_combined_sum.item() / init_val_batches\n",
    "        t_val_done = time.time()\n",
    "\n",
    "    # times\n",
    "    init_train_time = t_train_done - t_start\n",
    "    init_val_time   = t_val_done - t_train_done\n",
    "    init_total_time = t_val_done - t_start\n",
    "\n",
    "    csv_writer.writerow(csv_header)\n",
    "    # write initial row (epoch = None)\n",
    "    csv_writer.writerow([\n",
    "        None,\n",
    "        init_train_winner_loss,\n",
    "        init_train_action_loss,\n",
    "        init_train_combined_loss,\n",
    "        init_val_winner_loss,\n",
    "        init_val_action_loss,\n",
    "        init_val_combined_loss,\n",
    "        init_train_time,\n",
    "        init_val_time,\n",
    "        init_total_time,\n",
    "        combined_criterion.winner_err_log_scale.item(),\n",
    "        combined_criterion.action_err_log_scale.item()\n",
    "    ])\n",
    "    csv_file.flush()\n",
    "    print(\n",
    "        f\"Initial | Train Winner {init_train_winner_loss:.4f} | \"\n",
    "        f\"Train Action {init_train_action_loss:.4f} | \"\n",
    "        f\"Train Comb {init_train_combined_loss:.4f} | \"\n",
    "        f\"Val Winner {init_val_winner_loss:.4f} | \"\n",
    "        f\"Val Action {init_val_action_loss:.4f} | \"\n",
    "        f\"Val Comb {init_val_combined_loss:.4f} | \"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5862fa70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-261: 100%|██████████| 8/8 [05:56<00:00, 44.56s/it]\n",
      "val-epoch-261: 100%|██████████| 1/1 [00:35<00:00, 35.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261 | Train Winner 9.3602 | Train Action 26.7930 | Train Comb 22.4620 | Val Winner 1.3900 | Val Action 4.7365 | Val Comb 3.9536 | LR 0.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-262: 100%|██████████| 8/8 [05:50<00:00, 43.86s/it]\n",
      "val-epoch-262: 100%|██████████| 1/1 [00:34<00:00, 34.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 262 | Train Winner 1.1348 | Train Action 7.7746 | Train Comb 4.5918 | Val Winner 1.0699 | Val Action 3.0627 | Val Comb 3.3328 | LR 0.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-263: 100%|██████████| 8/8 [06:03<00:00, 45.42s/it]\n",
      "val-epoch-263: 100%|██████████| 1/1 [00:37<00:00, 37.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 263 | Train Winner 1.1060 | Train Action 4.8138 | Train Comb 3.7824 | Val Winner 1.0230 | Val Action 1.8654 | Val Comb 3.0043 | LR 0.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-264: 100%|██████████| 8/8 [06:14<00:00, 46.84s/it]\n",
      "val-epoch-264: 100%|██████████| 1/1 [00:39<00:00, 39.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 264 | Train Winner 1.0634 | Train Action 3.2129 | Train Comb 3.3511 | Val Winner 1.0552 | Val Action 1.5965 | Val Comb 2.9352 | LR 0.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-265: 100%|██████████| 8/8 [06:21<00:00, 47.65s/it]\n",
      "val-epoch-265: 100%|██████████| 1/1 [00:39<00:00, 39.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 265 | Train Winner 1.0498 | Train Action 2.4359 | Train Comb 3.1311 | Val Winner 1.0025 | Val Action 1.7853 | Val Comb 2.9224 | LR 0.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-266: 100%|██████████| 8/8 [06:26<00:00, 48.30s/it]\n",
      "val-epoch-266: 100%|██████████| 1/1 [00:38<00:00, 38.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 266 | Train Winner 1.0410 | Train Action 2.0226 | Train Comb 2.9945 | Val Winner 1.0059 | Val Action 2.1650 | Val Comb 2.9950 | LR 0.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-267: 100%|██████████| 8/8 [06:03<00:00, 45.46s/it]\n",
      "val-epoch-267: 100%|██████████| 1/1 [00:19<00:00, 19.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 267 | Train Winner 1.0395 | Train Action 1.8366 | Train Comb 2.9155 | Val Winner 1.0039 | Val Action 2.4063 | Val Comb 3.0346 | LR 0.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-268: 100%|██████████| 8/8 [02:29<00:00, 18.68s/it]\n",
      "val-epoch-268: 100%|██████████| 1/1 [00:12<00:00, 12.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 268 | Train Winner 1.0353 | Train Action 1.7672 | Train Comb 2.8648 | Val Winner 0.9904 | Val Action 2.3380 | Val Comb 2.9843 | LR 0.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-269: 100%|██████████| 8/8 [02:08<00:00, 16.07s/it]\n",
      "val-epoch-269: 100%|██████████| 1/1 [00:11<00:00, 11.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269 | Train Winner 1.0302 | Train Action 1.7208 | Train Comb 2.8202 | Val Winner 0.9913 | Val Action 2.2045 | Val Comb 2.9242 | LR 0.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-270: 100%|██████████| 8/8 [02:06<00:00, 15.87s/it]\n",
      "val-epoch-270: 100%|██████████| 1/1 [00:11<00:00, 11.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270 | Train Winner 1.0280 | Train Action 1.7046 | Train Comb 2.7876 | Val Winner 0.9848 | Val Action 2.0915 | Val Comb 2.8645 | LR 0.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-271: 100%|██████████| 8/8 [02:11<00:00, 16.45s/it]\n",
      "val-epoch-271: 100%|██████████| 1/1 [00:11<00:00, 11.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271 | Train Winner 1.0241 | Train Action 1.6893 | Train Comb 2.7558 | Val Winner 0.9829 | Val Action 2.0750 | Val Comb 2.8385 | LR 0.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-272: 100%|██████████| 8/8 [02:06<00:00, 15.80s/it]\n",
      "val-epoch-272: 100%|██████████| 1/1 [00:11<00:00, 11.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272 | Train Winner 1.0234 | Train Action 1.6738 | Train Comb 2.7276 | Val Winner 0.9803 | Val Action 2.0731 | Val Comb 2.8185 | LR 0.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-273: 100%|██████████| 8/8 [02:05<00:00, 15.74s/it]\n",
      "val-epoch-273: 100%|██████████| 1/1 [00:11<00:00, 11.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273 | Train Winner 1.0238 | Train Action 1.6700 | Train Comb 2.7058 | Val Winner 0.9783 | Val Action 2.0469 | Val Comb 2.7923 | LR 0.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-274: 100%|██████████| 8/8 [02:05<00:00, 15.69s/it]\n",
      "val-epoch-274: 100%|██████████| 1/1 [00:11<00:00, 11.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 274 | Train Winner 1.0236 | Train Action 1.6621 | Train Comb 2.6840 | Val Winner 0.9775 | Val Action 1.9947 | Val Comb 2.7588 | LR 0.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-275: 100%|██████████| 8/8 [02:05<00:00, 15.67s/it]\n",
      "val-epoch-275: 100%|██████████| 1/1 [00:11<00:00, 11.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275 | Train Winner 1.0208 | Train Action 1.6521 | Train Comb 2.6610 | Val Winner 0.9744 | Val Action 1.9533 | Val Comb 2.7279 | LR 0.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-276: 100%|██████████| 8/8 [02:05<00:00, 15.67s/it]\n",
      "val-epoch-276: 100%|██████████| 1/1 [00:11<00:00, 11.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276 | Train Winner 1.0160 | Train Action 1.6451 | Train Comb 2.6387 | Val Winner 0.9753 | Val Action 1.9209 | Val Comb 2.7040 | LR 0.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-277: 100%|██████████| 8/8 [02:05<00:00, 15.63s/it]\n",
      "val-epoch-277: 100%|██████████| 1/1 [00:11<00:00, 11.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277 | Train Winner 1.0196 | Train Action 1.6364 | Train Comb 2.6237 | Val Winner 0.9722 | Val Action 1.8852 | Val Comb 2.6765 | LR 0.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-278: 100%|██████████| 8/8 [02:04<00:00, 15.59s/it]\n",
      "val-epoch-278: 100%|██████████| 1/1 [00:11<00:00, 11.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278 | Train Winner 1.0172 | Train Action 1.6278 | Train Comb 2.6052 | Val Winner 0.9733 | Val Action 1.8507 | Val Comb 2.6531 | LR 0.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-279: 100%|██████████| 8/8 [02:04<00:00, 15.58s/it]\n",
      "val-epoch-279: 100%|██████████| 1/1 [00:11<00:00, 11.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279 | Train Winner 1.0170 | Train Action 1.6218 | Train Comb 2.5906 | Val Winner 0.9714 | Val Action 1.8206 | Val Comb 2.6297 | LR 0.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-280: 100%|██████████| 8/8 [02:04<00:00, 15.62s/it]\n",
      "val-epoch-280: 100%|██████████| 1/1 [00:11<00:00, 11.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280 | Train Winner 1.0156 | Train Action 1.6172 | Train Comb 2.5766 | Val Winner 0.9701 | Val Action 1.7938 | Val Comb 2.6086 | LR 0.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-281: 100%|██████████| 8/8 [02:05<00:00, 15.63s/it]\n",
      "val-epoch-281: 100%|██████████| 1/1 [00:11<00:00, 11.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281 | Train Winner 1.0139 | Train Action 1.6137 | Train Comb 2.5639 | Val Winner 0.9678 | Val Action 1.7750 | Val Comb 2.5906 | LR 0.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-282: 100%|██████████| 8/8 [02:04<00:00, 15.58s/it]\n",
      "val-epoch-282: 100%|██████████| 1/1 [00:11<00:00, 11.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282 | Train Winner 1.0111 | Train Action 1.6111 | Train Comb 2.5515 | Val Winner 0.9694 | Val Action 1.7566 | Val Comb 2.5767 | LR 0.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-283: 100%|██████████| 8/8 [02:40<00:00, 20.12s/it]\n",
      "val-epoch-283: 100%|██████████| 1/1 [00:14<00:00, 14.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283 | Train Winner 1.0115 | Train Action 1.6091 | Train Comb 2.5431 | Val Winner 0.9665 | Val Action 1.7280 | Val Comb 2.5548 | LR 0.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-284: 100%|██████████| 8/8 [02:16<00:00, 17.02s/it]\n",
      "val-epoch-284: 100%|██████████| 1/1 [00:12<00:00, 12.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284 | Train Winner 1.0084 | Train Action 1.6062 | Train Comb 2.5320 | Val Winner 0.9674 | Val Action 1.7098 | Val Comb 2.5411 | LR 0.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-285: 100%|██████████| 8/8 [02:08<00:00, 16.04s/it]\n",
      "val-epoch-285: 100%|██████████| 1/1 [00:11<00:00, 12.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285 | Train Winner 1.0079 | Train Action 1.6086 | Train Comb 2.5264 | Val Winner 0.9661 | Val Action 1.6905 | Val Comb 2.5256 | LR 0.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-286: 100%|██████████| 8/8 [02:07<00:00, 15.99s/it]\n",
      "val-epoch-286: 100%|██████████| 1/1 [00:12<00:00, 12.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286 | Train Winner 1.0074 | Train Action 1.6056 | Train Comb 2.5189 | Val Winner 0.9652 | Val Action 1.6734 | Val Comb 2.5117 | LR 0.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-287: 100%|██████████| 8/8 [02:08<00:00, 16.08s/it]\n",
      "val-epoch-287: 100%|██████████| 1/1 [00:11<00:00, 11.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287 | Train Winner 1.0067 | Train Action 1.6046 | Train Comb 2.5129 | Val Winner 0.9639 | Val Action 1.6532 | Val Comb 2.4962 | LR 0.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-288: 100%|██████████| 8/8 [02:08<00:00, 16.05s/it]\n",
      "val-epoch-288: 100%|██████████| 1/1 [00:12<00:00, 12.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288 | Train Winner 1.0058 | Train Action 1.6060 | Train Comb 2.5085 | Val Winner 0.9619 | Val Action 1.6458 | Val Comb 2.4867 | LR 0.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-289: 100%|██████████| 8/8 [02:08<00:00, 16.07s/it]\n",
      "val-epoch-289: 100%|██████████| 1/1 [00:12<00:00, 12.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289 | Train Winner 1.0042 | Train Action 1.6027 | Train Comb 2.5015 | Val Winner 0.9628 | Val Action 1.6330 | Val Comb 2.4775 | LR 0.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-290: 100%|██████████| 8/8 [02:08<00:00, 16.07s/it]\n",
      "val-epoch-290: 100%|██████████| 1/1 [00:11<00:00, 11.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290 | Train Winner 1.0025 | Train Action 1.5994 | Train Comb 2.4948 | Val Winner 0.9647 | Val Action 1.6158 | Val Comb 2.4671 | LR 0.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-291: 100%|██████████| 8/8 [02:07<00:00, 15.91s/it]\n",
      "val-epoch-291: 100%|██████████| 1/1 [00:12<00:00, 12.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291 | Train Winner 1.0035 | Train Action 1.5986 | Train Comb 2.4923 | Val Winner 0.9616 | Val Action 1.6139 | Val Comb 2.4603 | LR 0.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-292: 100%|██████████| 8/8 [02:08<00:00, 16.06s/it]\n",
      "val-epoch-292: 100%|██████████| 1/1 [00:12<00:00, 12.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 292 | Train Winner 1.0011 | Train Action 1.5990 | Train Comb 2.4877 | Val Winner 0.9610 | Val Action 1.6026 | Val Comb 2.4512 | LR 0.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-293: 100%|██████████| 8/8 [02:08<00:00, 16.03s/it]\n",
      "val-epoch-293: 100%|██████████| 1/1 [00:11<00:00, 11.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293 | Train Winner 0.9997 | Train Action 1.5976 | Train Comb 2.4833 | Val Winner 0.9617 | Val Action 1.5958 | Val Comb 2.4458 | LR 0.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-294: 100%|██████████| 8/8 [02:07<00:00, 15.97s/it]\n",
      "val-epoch-294: 100%|██████████| 1/1 [00:11<00:00, 11.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294 | Train Winner 1.0005 | Train Action 1.5990 | Train Comb 2.4827 | Val Winner 0.9590 | Val Action 1.5950 | Val Comb 2.4408 | LR 0.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-295: 100%|██████████| 8/8 [02:08<00:00, 16.03s/it]\n",
      "val-epoch-295: 100%|██████████| 1/1 [00:12<00:00, 12.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295 | Train Winner 0.9965 | Train Action 1.5978 | Train Comb 2.4766 | Val Winner 0.9633 | Val Action 1.5727 | Val Comb 2.4307 | LR 0.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-296: 100%|██████████| 8/8 [02:08<00:00, 16.01s/it]\n",
      "val-epoch-296: 100%|██████████| 1/1 [00:11<00:00, 11.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296 | Train Winner 0.9994 | Train Action 1.5946 | Train Comb 2.4759 | Val Winner 0.9578 | Val Action 1.5667 | Val Comb 2.4205 | LR 0.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-297: 100%|██████████| 8/8 [02:07<00:00, 15.93s/it]\n",
      "val-epoch-297: 100%|██████████| 1/1 [00:12<00:00, 12.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297 | Train Winner 0.9958 | Train Action 1.5943 | Train Comb 2.4710 | Val Winner 0.9596 | Val Action 1.5580 | Val Comb 2.4157 | LR 0.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-298: 100%|██████████| 8/8 [02:08<00:00, 16.01s/it]\n",
      "val-epoch-298: 100%|██████████| 1/1 [00:12<00:00, 12.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298 | Train Winner 0.9957 | Train Action 1.5920 | Train Comb 2.4684 | Val Winner 0.9544 | Val Action 1.5527 | Val Comb 2.4063 | LR 0.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-299: 100%|██████████| 8/8 [02:08<00:00, 16.03s/it]\n",
      "val-epoch-299: 100%|██████████| 1/1 [00:12<00:00, 12.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299 | Train Winner 0.9944 | Train Action 1.5937 | Train Comb 2.4671 | Val Winner 0.9544 | Val Action 1.5475 | Val Comb 2.4020 | LR 0.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-300: 100%|██████████| 8/8 [02:08<00:00, 16.06s/it]\n",
      "val-epoch-300: 100%|██████████| 1/1 [00:11<00:00, 11.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300 | Train Winner 0.9957 | Train Action 1.5917 | Train Comb 2.4662 | Val Winner 0.9593 | Val Action 1.5480 | Val Comb 2.4058 | LR 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-301: 100%|██████████| 8/8 [02:07<00:00, 15.97s/it]\n",
      "val-epoch-301: 100%|██████████| 1/1 [00:12<00:00, 12.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301 | Train Winner 0.9948 | Train Action 1.5921 | Train Comb 2.4648 | Val Winner 0.9600 | Val Action 1.5456 | Val Comb 2.4040 | LR 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-302: 100%|██████████| 8/8 [02:11<00:00, 16.38s/it]\n",
      "val-epoch-302: 100%|██████████| 1/1 [00:12<00:00, 12.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 302 | Train Winner 0.9929 | Train Action 1.5919 | Train Comb 2.4622 | Val Winner 0.9573 | Val Action 1.5480 | Val Comb 2.4019 | LR 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-303: 100%|██████████| 8/8 [02:08<00:00, 16.02s/it]\n",
      "val-epoch-303: 100%|██████████| 1/1 [00:12<00:00, 12.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 303 | Train Winner 0.9925 | Train Action 1.5924 | Train Comb 2.4614 | Val Winner 0.9597 | Val Action 1.5458 | Val Comb 2.4021 | LR 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-304: 100%|██████████| 8/8 [02:07<00:00, 15.94s/it]\n",
      "val-epoch-304: 100%|██████████| 1/1 [00:12<00:00, 12.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304 | Train Winner 0.9912 | Train Action 1.5887 | Train Comb 2.4574 | Val Winner 0.9564 | Val Action 1.5427 | Val Comb 2.3964 | LR 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-305: 100%|██████████| 8/8 [02:07<00:00, 15.90s/it]\n",
      "val-epoch-305: 100%|██████████| 1/1 [00:11<00:00, 11.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305 | Train Winner 0.9910 | Train Action 1.5877 | Train Comb 2.4561 | Val Winner 0.9589 | Val Action 1.5438 | Val Comb 2.3987 | LR 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-306: 100%|██████████| 8/8 [02:07<00:00, 15.96s/it]\n",
      "val-epoch-306: 100%|██████████| 1/1 [00:12<00:00, 12.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306 | Train Winner 0.9894 | Train Action 1.5889 | Train Comb 2.4550 | Val Winner 0.9560 | Val Action 1.5373 | Val Comb 2.3915 | LR 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-307: 100%|██████████| 8/8 [02:07<00:00, 15.91s/it]\n",
      "val-epoch-307: 100%|██████████| 1/1 [00:11<00:00, 11.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 307 | Train Winner 0.9892 | Train Action 1.5872 | Train Comb 2.4534 | Val Winner 0.9507 | Val Action 1.5266 | Val Comb 2.3793 | LR 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-308: 100%|██████████| 8/8 [02:07<00:00, 15.96s/it]\n",
      "val-epoch-308: 100%|██████████| 1/1 [00:11<00:00, 11.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308 | Train Winner 0.9892 | Train Action 1.5890 | Train Comb 2.4541 | Val Winner 0.9567 | Val Action 1.5277 | Val Comb 2.3853 | LR 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-309: 100%|██████████| 8/8 [02:07<00:00, 15.94s/it]\n",
      "val-epoch-309: 100%|██████████| 1/1 [00:11<00:00, 11.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309 | Train Winner 0.9882 | Train Action 1.5896 | Train Comb 2.4532 | Val Winner 0.9523 | Val Action 1.5305 | Val Comb 2.3822 | LR 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-310: 100%|██████████| 8/8 [02:07<00:00, 15.97s/it]\n",
      "val-epoch-310: 100%|██████████| 1/1 [00:11<00:00, 11.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 310 | Train Winner 0.9874 | Train Action 1.5863 | Train Comb 2.4502 | Val Winner 0.9501 | Val Action 1.5234 | Val Comb 2.3754 | LR 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-311: 100%|██████████| 8/8 [02:07<00:00, 15.97s/it]\n",
      "val-epoch-311: 100%|██████████| 1/1 [00:11<00:00, 11.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 311 | Train Winner 0.9875 | Train Action 1.5855 | Train Comb 2.4496 | Val Winner 0.9475 | Val Action 1.5191 | Val Comb 2.3698 | LR 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-312: 100%|██████████| 8/8 [02:07<00:00, 15.94s/it]\n",
      "val-epoch-312: 100%|██████████| 1/1 [00:11<00:00, 11.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 312 | Train Winner 0.9879 | Train Action 1.5838 | Train Comb 2.4488 | Val Winner 0.9542 | Val Action 1.5227 | Val Comb 2.3782 | LR 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-313: 100%|██████████| 8/8 [02:07<00:00, 15.95s/it]\n",
      "val-epoch-313: 100%|██████████| 1/1 [00:11<00:00, 11.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313 | Train Winner 0.9856 | Train Action 1.5845 | Train Comb 2.4467 | Val Winner 0.9454 | Val Action 1.5223 | Val Comb 2.3689 | LR 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-314: 100%|██████████| 8/8 [02:07<00:00, 15.88s/it]\n",
      "val-epoch-314: 100%|██████████| 1/1 [00:11<00:00, 11.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 314 | Train Winner 0.9869 | Train Action 1.5843 | Train Comb 2.4478 | Val Winner 0.9467 | Val Action 1.5260 | Val Comb 2.3722 | LR 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-315: 100%|██████████| 8/8 [02:07<00:00, 15.93s/it]\n",
      "val-epoch-315: 100%|██████████| 1/1 [00:12<00:00, 12.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 315 | Train Winner 0.9865 | Train Action 1.5856 | Train Comb 2.4481 | Val Winner 0.9451 | Val Action 1.5221 | Val Comb 2.3679 | LR 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-316: 100%|██████████| 8/8 [02:08<00:00, 16.03s/it]\n",
      "val-epoch-316: 100%|██████████| 1/1 [00:12<00:00, 12.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 316 | Train Winner 0.9856 | Train Action 1.5844 | Train Comb 2.4463 | Val Winner 0.9496 | Val Action 1.5201 | Val Comb 2.3709 | LR 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-317: 100%|██████████| 8/8 [02:08<00:00, 16.00s/it]\n",
      "val-epoch-317: 100%|██████████| 1/1 [00:12<00:00, 12.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317 | Train Winner 0.9850 | Train Action 1.5839 | Train Comb 2.4454 | Val Winner 0.9575 | Val Action 1.5215 | Val Comb 2.3795 | LR 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-318: 100%|██████████| 8/8 [02:08<00:00, 16.01s/it]\n",
      "val-epoch-318: 100%|██████████| 1/1 [00:12<00:00, 12.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318 | Train Winner 0.9853 | Train Action 1.5837 | Train Comb 2.4454 | Val Winner 0.9574 | Val Action 1.5199 | Val Comb 2.3783 | LR 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-319: 100%|██████████| 8/8 [02:08<00:00, 16.00s/it]\n",
      "val-epoch-319: 100%|██████████| 1/1 [00:12<00:00, 12.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 319 | Train Winner 0.9860 | Train Action 1.5824 | Train Comb 2.4453 | Val Winner 0.9600 | Val Action 1.5230 | Val Comb 2.3826 | LR 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-320: 100%|██████████| 8/8 [02:07<00:00, 15.97s/it]\n",
      "val-epoch-320: 100%|██████████| 1/1 [00:11<00:00, 11.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 320 | Train Winner 0.9859 | Train Action 1.5815 | Train Comb 2.4445 | Val Winner 0.9568 | Val Action 1.5182 | Val Comb 2.3763 | LR 0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-321: 100%|██████████| 8/8 [02:08<00:00, 16.06s/it]\n",
      "val-epoch-321: 100%|██████████| 1/1 [00:12<00:00, 12.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 321 | Train Winner 0.9831 | Train Action 1.5819 | Train Comb 2.4419 | Val Winner 0.9503 | Val Action 1.5216 | Val Comb 2.3717 | LR 0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-322: 100%|██████████| 8/8 [02:08<00:00, 16.03s/it]\n",
      "val-epoch-322: 100%|██████████| 1/1 [00:12<00:00, 12.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 322 | Train Winner 0.9835 | Train Action 1.5829 | Train Comb 2.4429 | Val Winner 0.9514 | Val Action 1.5133 | Val Comb 2.3675 | LR 0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-323: 100%|██████████| 8/8 [02:08<00:00, 16.00s/it]\n",
      "val-epoch-323: 100%|██████████| 1/1 [00:11<00:00, 11.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 323 | Train Winner 0.9834 | Train Action 1.5817 | Train Comb 2.4420 | Val Winner 0.9528 | Val Action 1.5143 | Val Comb 2.3694 | LR 0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-324: 100%|██████████| 8/8 [02:07<00:00, 15.95s/it]\n",
      "val-epoch-324: 100%|██████████| 1/1 [00:12<00:00, 12.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 324 | Train Winner 0.9844 | Train Action 1.5821 | Train Comb 2.4432 | Val Winner 0.9435 | Val Action 1.5188 | Val Comb 2.3627 | LR 0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-325: 100%|██████████| 8/8 [02:07<00:00, 15.99s/it]\n",
      "val-epoch-325: 100%|██████████| 1/1 [00:12<00:00, 12.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 325 | Train Winner 0.9805 | Train Action 1.5786 | Train Comb 2.4371 | Val Winner 0.9452 | Val Action 1.5115 | Val Comb 2.3597 | LR 0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-326: 100%|██████████| 8/8 [02:07<00:00, 15.96s/it]\n",
      "val-epoch-326: 100%|██████████| 1/1 [00:11<00:00, 11.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 326 | Train Winner 0.9852 | Train Action 1.5816 | Train Comb 2.4436 | Val Winner 0.9455 | Val Action 1.5185 | Val Comb 2.3643 | LR 0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-327: 100%|██████████| 8/8 [02:36<00:00, 19.54s/it]\n",
      "val-epoch-327: 100%|██████████| 1/1 [00:23<00:00, 23.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 327 | Train Winner 0.9842 | Train Action 1.5809 | Train Comb 2.4422 | Val Winner 0.9476 | Val Action 1.5131 | Val Comb 2.3629 | LR 0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-328: 100%|██████████| 8/8 [02:18<00:00, 17.31s/it]\n",
      "val-epoch-328: 100%|██████████| 1/1 [00:11<00:00, 11.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 328 | Train Winner 0.9838 | Train Action 1.5785 | Train Comb 2.4403 | Val Winner 0.9496 | Val Action 1.5144 | Val Comb 2.3658 | LR 0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-329: 100%|██████████| 8/8 [02:06<00:00, 15.80s/it]\n",
      "val-epoch-329: 100%|██████████| 1/1 [00:11<00:00, 11.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329 | Train Winner 0.9835 | Train Action 1.5785 | Train Comb 2.4399 | Val Winner 0.9453 | Val Action 1.5132 | Val Comb 2.3606 | LR 0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-330: 100%|██████████| 8/8 [02:06<00:00, 15.77s/it]\n",
      "val-epoch-330: 100%|██████████| 1/1 [00:11<00:00, 11.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330 | Train Winner 0.9820 | Train Action 1.5786 | Train Comb 2.4385 | Val Winner 0.9484 | Val Action 1.5119 | Val Comb 2.3628 | LR 0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-331: 100%|██████████| 8/8 [02:05<00:00, 15.71s/it]\n",
      "val-epoch-331: 100%|██████████| 1/1 [00:11<00:00, 11.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331 | Train Winner 0.9797 | Train Action 1.5773 | Train Comb 2.4354 | Val Winner 0.9543 | Val Action 1.5113 | Val Comb 2.3682 | LR 0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-332: 100%|██████████| 8/8 [02:05<00:00, 15.70s/it]\n",
      "val-epoch-332: 100%|██████████| 1/1 [00:11<00:00, 11.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 332 | Train Winner 0.9820 | Train Action 1.5775 | Train Comb 2.4377 | Val Winner 0.9546 | Val Action 1.5131 | Val Comb 2.3696 | LR 0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-333: 100%|██████████| 8/8 [02:22<00:00, 17.86s/it]\n",
      "val-epoch-333: 100%|██████████| 1/1 [00:11<00:00, 11.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333 | Train Winner 0.9821 | Train Action 1.5781 | Train Comb 2.4382 | Val Winner 0.9522 | Val Action 1.5099 | Val Comb 2.3651 | LR 0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-334: 100%|██████████| 8/8 [02:04<00:00, 15.61s/it]\n",
      "val-epoch-334: 100%|██████████| 1/1 [00:12<00:00, 12.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334 | Train Winner 0.9826 | Train Action 1.5791 | Train Comb 2.4394 | Val Winner 0.9507 | Val Action 1.5089 | Val Comb 2.3629 | LR 0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-335: 100%|██████████| 8/8 [02:08<00:00, 16.02s/it]\n",
      "val-epoch-335: 100%|██████████| 1/1 [00:12<00:00, 12.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335 | Train Winner 0.9817 | Train Action 1.5766 | Train Comb 2.4369 | Val Winner 0.9479 | Val Action 1.5108 | Val Comb 2.3613 | LR 0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-336: 100%|██████████| 8/8 [02:07<00:00, 15.90s/it]\n",
      "val-epoch-336: 100%|██████████| 1/1 [00:11<00:00, 11.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336 | Train Winner 0.9793 | Train Action 1.5783 | Train Comb 2.4355 | Val Winner 0.9504 | Val Action 1.5052 | Val Comb 2.3602 | LR 0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-337: 100%|██████████| 8/8 [02:02<00:00, 15.36s/it]\n",
      "val-epoch-337: 100%|██████████| 1/1 [00:11<00:00, 11.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337 | Train Winner 0.9787 | Train Action 1.5763 | Train Comb 2.4336 | Val Winner 0.9493 | Val Action 1.5105 | Val Comb 2.3624 | LR 0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-338: 100%|██████████| 8/8 [02:01<00:00, 15.22s/it]\n",
      "val-epoch-338: 100%|██████████| 1/1 [00:11<00:00, 11.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338 | Train Winner 0.9797 | Train Action 1.5766 | Train Comb 2.4348 | Val Winner 0.9487 | Val Action 1.5018 | Val Comb 2.3562 | LR 0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-339: 100%|██████████| 8/8 [02:01<00:00, 15.17s/it]\n",
      "val-epoch-339: 100%|██████████| 1/1 [00:11<00:00, 11.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 339 | Train Winner 0.9806 | Train Action 1.5763 | Train Comb 2.4356 | Val Winner 0.9532 | Val Action 1.5001 | Val Comb 2.3597 | LR 0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-340: 100%|██████████| 8/8 [02:02<00:00, 15.29s/it]\n",
      "val-epoch-340: 100%|██████████| 1/1 [00:11<00:00, 11.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 340 | Train Winner 0.9792 | Train Action 1.5741 | Train Comb 2.4327 | Val Winner 0.9468 | Val Action 1.5009 | Val Comb 2.3537 | LR 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-341: 100%|██████████| 8/8 [02:02<00:00, 15.33s/it]\n",
      "val-epoch-341: 100%|██████████| 1/1 [00:11<00:00, 11.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 341 | Train Winner 0.9802 | Train Action 1.5755 | Train Comb 2.4346 | Val Winner 0.9531 | Val Action 1.4972 | Val Comb 2.3577 | LR 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-342: 100%|██████████| 8/8 [02:02<00:00, 15.35s/it]\n",
      "val-epoch-342: 100%|██████████| 1/1 [00:11<00:00, 11.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342 | Train Winner 0.9827 | Train Action 1.5740 | Train Comb 2.4362 | Val Winner 0.9421 | Val Action 1.4910 | Val Comb 2.3426 | LR 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-343: 100%|██████████| 8/8 [02:02<00:00, 15.32s/it]\n",
      "val-epoch-343: 100%|██████████| 1/1 [00:11<00:00, 11.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343 | Train Winner 0.9782 | Train Action 1.5740 | Train Comb 2.4316 | Val Winner 0.9426 | Val Action 1.4942 | Val Comb 2.3450 | LR 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-344: 100%|██████████| 8/8 [02:01<00:00, 15.21s/it]\n",
      "val-epoch-344: 100%|██████████| 1/1 [00:11<00:00, 11.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344 | Train Winner 0.9815 | Train Action 1.5753 | Train Comb 2.4359 | Val Winner 0.9477 | Val Action 1.4932 | Val Comb 2.3496 | LR 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-345: 100%|██████████| 8/8 [02:01<00:00, 15.18s/it]\n",
      "val-epoch-345: 100%|██████████| 1/1 [00:11<00:00, 11.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 345 | Train Winner 0.9816 | Train Action 1.5768 | Train Comb 2.4368 | Val Winner 0.9452 | Val Action 1.4915 | Val Comb 2.3459 | LR 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-346: 100%|██████████| 8/8 [02:01<00:00, 15.18s/it]\n",
      "val-epoch-346: 100%|██████████| 1/1 [00:11<00:00, 11.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346 | Train Winner 0.9783 | Train Action 1.5733 | Train Comb 2.4313 | Val Winner 0.9497 | Val Action 1.4932 | Val Comb 2.3515 | LR 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-347: 100%|██████████| 8/8 [02:01<00:00, 15.23s/it]\n",
      "val-epoch-347: 100%|██████████| 1/1 [00:11<00:00, 11.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 347 | Train Winner 0.9796 | Train Action 1.5722 | Train Comb 2.4319 | Val Winner 0.9466 | Val Action 1.4864 | Val Comb 2.3440 | LR 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-348: 100%|██████████| 8/8 [02:01<00:00, 15.20s/it]\n",
      "val-epoch-348: 100%|██████████| 1/1 [00:11<00:00, 11.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 348 | Train Winner 0.9798 | Train Action 1.5736 | Train Comb 2.4330 | Val Winner 0.9436 | Val Action 1.4809 | Val Comb 2.3375 | LR 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-349: 100%|██████████| 8/8 [02:01<00:00, 15.22s/it]\n",
      "val-epoch-349: 100%|██████████| 1/1 [00:11<00:00, 11.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349 | Train Winner 0.9820 | Train Action 1.5723 | Train Comb 2.4344 | Val Winner 0.9381 | Val Action 1.4761 | Val Comb 2.3288 | LR 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-350: 100%|██████████| 8/8 [02:01<00:00, 15.23s/it]\n",
      "val-epoch-350: 100%|██████████| 1/1 [00:11<00:00, 11.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350 | Train Winner 0.9784 | Train Action 1.5729 | Train Comb 2.4310 | Val Winner 0.9450 | Val Action 1.4769 | Val Comb 2.3362 | LR 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-351: 100%|██████████| 8/8 [02:01<00:00, 15.19s/it]\n",
      "val-epoch-351: 100%|██████████| 1/1 [00:11<00:00, 11.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351 | Train Winner 0.9785 | Train Action 1.5734 | Train Comb 2.4315 | Val Winner 0.9445 | Val Action 1.4739 | Val Comb 2.3338 | LR 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-352: 100%|██████████| 8/8 [02:01<00:00, 15.19s/it]\n",
      "val-epoch-352: 100%|██████████| 1/1 [00:11<00:00, 11.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 352 | Train Winner 0.9779 | Train Action 1.5734 | Train Comb 2.4309 | Val Winner 0.9451 | Val Action 1.4710 | Val Comb 2.3326 | LR 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-353: 100%|██████████| 8/8 [02:03<00:00, 15.45s/it]\n",
      "val-epoch-353: 100%|██████████| 1/1 [00:12<00:00, 12.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 353 | Train Winner 0.9763 | Train Action 1.5736 | Train Comb 2.4294 | Val Winner 0.9527 | Val Action 1.4649 | Val Comb 2.3365 | LR 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-354: 100%|██████████| 8/8 [02:04<00:00, 15.51s/it]\n",
      "val-epoch-354: 100%|██████████| 1/1 [00:11<00:00, 11.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354 | Train Winner 0.9789 | Train Action 1.5736 | Train Comb 2.4320 | Val Winner 0.9427 | Val Action 1.4653 | Val Comb 2.3265 | LR 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-355: 100%|██████████| 8/8 [02:02<00:00, 15.25s/it]\n",
      "val-epoch-355: 100%|██████████| 1/1 [00:11<00:00, 11.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355 | Train Winner 0.9795 | Train Action 1.5708 | Train Comb 2.4309 | Val Winner 0.9418 | Val Action 1.4635 | Val Comb 2.3245 | LR 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-356: 100%|██████████| 8/8 [02:02<00:00, 15.28s/it]\n",
      "val-epoch-356: 100%|██████████| 1/1 [00:11<00:00, 11.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 356 | Train Winner 0.9794 | Train Action 1.5727 | Train Comb 2.4320 | Val Winner 0.9404 | Val Action 1.4580 | Val Comb 2.3194 | LR 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-357: 100%|██████████| 8/8 [02:02<00:00, 15.27s/it]\n",
      "val-epoch-357: 100%|██████████| 1/1 [00:11<00:00, 11.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 357 | Train Winner 0.9779 | Train Action 1.5706 | Train Comb 2.4291 | Val Winner 0.9413 | Val Action 1.4543 | Val Comb 2.3180 | LR 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-358: 100%|██████████| 8/8 [02:02<00:00, 15.29s/it]\n",
      "val-epoch-358: 100%|██████████| 1/1 [00:11<00:00, 11.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 358 | Train Winner 0.9781 | Train Action 1.5715 | Train Comb 2.4298 | Val Winner 0.9424 | Val Action 1.4584 | Val Comb 2.3216 | LR 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-359: 100%|██████████| 8/8 [02:03<00:00, 15.40s/it]\n",
      "val-epoch-359: 100%|██████████| 1/1 [00:11<00:00, 11.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359 | Train Winner 0.9783 | Train Action 1.5716 | Train Comb 2.4301 | Val Winner 0.9456 | Val Action 1.4556 | Val Comb 2.3231 | LR 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-360: 100%|██████████| 8/8 [02:01<00:00, 15.18s/it]\n",
      "val-epoch-360: 100%|██████████| 1/1 [00:11<00:00, 11.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360 | Train Winner 0.9781 | Train Action 1.5702 | Train Comb 2.4291 | Val Winner 0.9457 | Val Action 1.4531 | Val Comb 2.3216 | LR 0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-361: 100%|██████████| 8/8 [02:01<00:00, 15.19s/it]\n",
      "val-epoch-361: 100%|██████████| 1/1 [00:11<00:00, 11.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361 | Train Winner 0.9785 | Train Action 1.5722 | Train Comb 2.4308 | Val Winner 0.9438 | Val Action 1.4509 | Val Comb 2.3184 | LR 0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-362: 100%|██████████| 8/8 [02:01<00:00, 15.18s/it]\n",
      "val-epoch-362: 100%|██████████| 1/1 [00:11<00:00, 11.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 362 | Train Winner 0.9777 | Train Action 1.5709 | Train Comb 2.4292 | Val Winner 0.9448 | Val Action 1.4509 | Val Comb 2.3193 | LR 0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-363: 100%|██████████| 8/8 [02:01<00:00, 15.15s/it]\n",
      "val-epoch-363: 100%|██████████| 1/1 [00:11<00:00, 11.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 363 | Train Winner 0.9775 | Train Action 1.5702 | Train Comb 2.4284 | Val Winner 0.9457 | Val Action 1.4471 | Val Comb 2.3179 | LR 0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-364: 100%|██████████| 8/8 [02:01<00:00, 15.15s/it]\n",
      "val-epoch-364: 100%|██████████| 1/1 [00:11<00:00, 11.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 364 | Train Winner 0.9772 | Train Action 1.5700 | Train Comb 2.4280 | Val Winner 0.9412 | Val Action 1.4444 | Val Comb 2.3115 | LR 0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-365: 100%|██████████| 8/8 [02:01<00:00, 15.16s/it]\n",
      "val-epoch-365: 100%|██████████| 1/1 [00:11<00:00, 11.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 365 | Train Winner 0.9776 | Train Action 1.5701 | Train Comb 2.4285 | Val Winner 0.9407 | Val Action 1.4490 | Val Comb 2.3138 | LR 0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-366: 100%|██████████| 8/8 [02:01<00:00, 15.16s/it]\n",
      "val-epoch-366: 100%|██████████| 1/1 [00:11<00:00, 11.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 366 | Train Winner 0.9763 | Train Action 1.5684 | Train Comb 2.4260 | Val Winner 0.9447 | Val Action 1.4448 | Val Comb 2.3152 | LR 0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-367: 100%|██████████| 8/8 [02:01<00:00, 15.17s/it]\n",
      "val-epoch-367: 100%|██████████| 1/1 [00:11<00:00, 11.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367 | Train Winner 0.9777 | Train Action 1.5695 | Train Comb 2.4281 | Val Winner 0.9437 | Val Action 1.4455 | Val Comb 2.3146 | LR 0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-368: 100%|██████████| 8/8 [02:05<00:00, 15.70s/it]\n",
      "val-epoch-368: 100%|██████████| 1/1 [00:11<00:00, 11.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 368 | Train Winner 0.9752 | Train Action 1.5685 | Train Comb 2.4250 | Val Winner 0.9466 | Val Action 1.4427 | Val Comb 2.3158 | LR 0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-369: 100%|██████████| 8/8 [02:10<00:00, 16.32s/it]\n",
      "val-epoch-369: 100%|██████████| 1/1 [00:12<00:00, 12.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369 | Train Winner 0.9769 | Train Action 1.5691 | Train Comb 2.4271 | Val Winner 0.9438 | Val Action 1.4426 | Val Comb 2.3129 | LR 0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-370: 100%|██████████| 8/8 [02:12<00:00, 16.57s/it]\n",
      "val-epoch-370: 100%|██████████| 1/1 [00:12<00:00, 12.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 370 | Train Winner 0.9751 | Train Action 1.5721 | Train Comb 2.4272 | Val Winner 0.9401 | Val Action 1.4416 | Val Comb 2.3084 | LR 0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-371: 100%|██████████| 8/8 [02:12<00:00, 16.62s/it]\n",
      "val-epoch-371: 100%|██████████| 1/1 [00:12<00:00, 12.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371 | Train Winner 0.9779 | Train Action 1.5687 | Train Comb 2.4279 | Val Winner 0.9429 | Val Action 1.4406 | Val Comb 2.3106 | LR 0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-372: 100%|██████████| 8/8 [02:01<00:00, 15.24s/it]\n",
      "val-epoch-372: 100%|██████████| 1/1 [00:11<00:00, 11.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 372 | Train Winner 0.9783 | Train Action 1.5722 | Train Comb 2.4305 | Val Winner 0.9405 | Val Action 1.4426 | Val Comb 2.3095 | LR 0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-373: 100%|██████████| 8/8 [02:03<00:00, 15.50s/it]\n",
      "val-epoch-373: 100%|██████████| 1/1 [00:11<00:00, 11.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 373 | Train Winner 0.9771 | Train Action 1.5711 | Train Comb 2.4286 | Val Winner 0.9458 | Val Action 1.4391 | Val Comb 2.3127 | LR 0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-374: 100%|██████████| 8/8 [02:03<00:00, 15.50s/it]\n",
      "val-epoch-374: 100%|██████████| 1/1 [00:11<00:00, 11.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 374 | Train Winner 0.9785 | Train Action 1.5712 | Train Comb 2.4301 | Val Winner 0.9483 | Val Action 1.4397 | Val Comb 2.3156 | LR 0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-375: 100%|██████████| 8/8 [02:04<00:00, 15.51s/it]\n",
      "val-epoch-375: 100%|██████████| 1/1 [00:11<00:00, 11.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 375 | Train Winner 0.9776 | Train Action 1.5698 | Train Comb 2.4283 | Val Winner 0.9415 | Val Action 1.4460 | Val Comb 2.3127 | LR 0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-376: 100%|██████████| 8/8 [02:04<00:00, 15.60s/it]\n",
      "val-epoch-376: 100%|██████████| 1/1 [00:11<00:00, 11.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376 | Train Winner 0.9773 | Train Action 1.5692 | Train Comb 2.4276 | Val Winner 0.9391 | Val Action 1.4417 | Val Comb 2.3074 | LR 0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-377: 100%|██████████| 8/8 [02:04<00:00, 15.57s/it]\n",
      "val-epoch-377: 100%|██████████| 1/1 [00:11<00:00, 11.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 377 | Train Winner 0.9748 | Train Action 1.5704 | Train Comb 2.4258 | Val Winner 0.9511 | Val Action 1.4428 | Val Comb 2.3203 | LR 0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-378: 100%|██████████| 8/8 [02:04<00:00, 15.58s/it]\n",
      "val-epoch-378: 100%|██████████| 1/1 [00:11<00:00, 11.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 378 | Train Winner 0.9755 | Train Action 1.5689 | Train Comb 2.4255 | Val Winner 0.9463 | Val Action 1.4387 | Val Comb 2.3129 | LR 0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-379: 100%|██████████| 8/8 [02:04<00:00, 15.54s/it]\n",
      "val-epoch-379: 100%|██████████| 1/1 [00:11<00:00, 11.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379 | Train Winner 0.9762 | Train Action 1.5692 | Train Comb 2.4265 | Val Winner 0.9460 | Val Action 1.4378 | Val Comb 2.3119 | LR 0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-380: 100%|██████████| 8/8 [02:04<00:00, 15.59s/it]\n",
      "val-epoch-380: 100%|██████████| 1/1 [00:11<00:00, 11.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380 | Train Winner 0.9752 | Train Action 1.5682 | Train Comb 2.4249 | Val Winner 0.9466 | Val Action 1.4397 | Val Comb 2.3138 | LR 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-381: 100%|██████████| 8/8 [02:04<00:00, 15.59s/it]\n",
      "val-epoch-381: 100%|██████████| 1/1 [00:11<00:00, 11.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381 | Train Winner 0.9758 | Train Action 1.5665 | Train Comb 2.4243 | Val Winner 0.9464 | Val Action 1.4399 | Val Comb 2.3136 | LR 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-382: 100%|██████████| 8/8 [02:04<00:00, 15.54s/it]\n",
      "val-epoch-382: 100%|██████████| 1/1 [00:11<00:00, 11.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 382 | Train Winner 0.9756 | Train Action 1.5691 | Train Comb 2.4258 | Val Winner 0.9428 | Val Action 1.4384 | Val Comb 2.3090 | LR 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-383: 100%|██████████| 8/8 [02:04<00:00, 15.56s/it]\n",
      "val-epoch-383: 100%|██████████| 1/1 [00:11<00:00, 11.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 383 | Train Winner 0.9755 | Train Action 1.5690 | Train Comb 2.4256 | Val Winner 0.9456 | Val Action 1.4377 | Val Comb 2.3114 | LR 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-384: 100%|██████████| 8/8 [02:04<00:00, 15.55s/it]\n",
      "val-epoch-384: 100%|██████████| 1/1 [00:11<00:00, 11.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 384 | Train Winner 0.9760 | Train Action 1.5677 | Train Comb 2.4253 | Val Winner 0.9435 | Val Action 1.4415 | Val Comb 2.3116 | LR 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-385: 100%|██████████| 8/8 [02:11<00:00, 16.45s/it]\n",
      "val-epoch-385: 100%|██████████| 1/1 [00:11<00:00, 11.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385 | Train Winner 0.9771 | Train Action 1.5696 | Train Comb 2.4277 | Val Winner 0.9436 | Val Action 1.4385 | Val Comb 2.3099 | LR 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-386: 100%|██████████| 8/8 [02:06<00:00, 15.81s/it]\n",
      "val-epoch-386: 100%|██████████| 1/1 [00:11<00:00, 11.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386 | Train Winner 0.9754 | Train Action 1.5697 | Train Comb 2.4260 | Val Winner 0.9448 | Val Action 1.4418 | Val Comb 2.3131 | LR 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-387: 100%|██████████| 8/8 [02:06<00:00, 15.85s/it]\n",
      "val-epoch-387: 100%|██████████| 1/1 [00:12<00:00, 12.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387 | Train Winner 0.9767 | Train Action 1.5674 | Train Comb 2.4259 | Val Winner 0.9441 | Val Action 1.4368 | Val Comb 2.3093 | LR 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-388: 100%|██████████| 8/8 [02:06<00:00, 15.81s/it]\n",
      "val-epoch-388: 100%|██████████| 1/1 [00:11<00:00, 11.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388 | Train Winner 0.9748 | Train Action 1.5685 | Train Comb 2.4246 | Val Winner 0.9403 | Val Action 1.4362 | Val Comb 2.3049 | LR 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-389: 100%|██████████| 8/8 [02:06<00:00, 15.80s/it]\n",
      "val-epoch-389: 100%|██████████| 1/1 [00:11<00:00, 11.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389 | Train Winner 0.9772 | Train Action 1.5662 | Train Comb 2.4256 | Val Winner 0.9431 | Val Action 1.4317 | Val Comb 2.3049 | LR 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-390: 100%|██████████| 8/8 [02:06<00:00, 15.84s/it]\n",
      "val-epoch-390: 100%|██████████| 1/1 [00:11<00:00, 11.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390 | Train Winner 0.9761 | Train Action 1.5677 | Train Comb 2.4254 | Val Winner 0.9434 | Val Action 1.4355 | Val Comb 2.3077 | LR 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-391: 100%|██████████| 8/8 [02:06<00:00, 15.84s/it]\n",
      "val-epoch-391: 100%|██████████| 1/1 [00:11<00:00, 11.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391 | Train Winner 0.9783 | Train Action 1.5679 | Train Comb 2.4278 | Val Winner 0.9380 | Val Action 1.4343 | Val Comb 2.3013 | LR 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-392: 100%|██████████| 8/8 [02:06<00:00, 15.82s/it]\n",
      "val-epoch-392: 100%|██████████| 1/1 [00:11<00:00, 11.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392 | Train Winner 0.9769 | Train Action 1.5686 | Train Comb 2.4268 | Val Winner 0.9416 | Val Action 1.4360 | Val Comb 2.3061 | LR 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-393: 100%|██████████| 8/8 [02:06<00:00, 15.80s/it]\n",
      "val-epoch-393: 100%|██████████| 1/1 [00:11<00:00, 11.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393 | Train Winner 0.9745 | Train Action 1.5670 | Train Comb 2.4234 | Val Winner 0.9436 | Val Action 1.4336 | Val Comb 2.3067 | LR 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-394: 100%|██████████| 8/8 [02:06<00:00, 15.79s/it]\n",
      "val-epoch-394: 100%|██████████| 1/1 [00:11<00:00, 11.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 394 | Train Winner 0.9771 | Train Action 1.5694 | Train Comb 2.4275 | Val Winner 0.9482 | Val Action 1.4333 | Val Comb 2.3112 | LR 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-395: 100%|██████████| 8/8 [02:06<00:00, 15.79s/it]\n",
      "val-epoch-395: 100%|██████████| 1/1 [00:11<00:00, 11.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395 | Train Winner 0.9756 | Train Action 1.5676 | Train Comb 2.4249 | Val Winner 0.9414 | Val Action 1.4340 | Val Comb 2.3047 | LR 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-396: 100%|██████████| 8/8 [02:06<00:00, 15.80s/it]\n",
      "val-epoch-396: 100%|██████████| 1/1 [00:11<00:00, 11.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396 | Train Winner 0.9739 | Train Action 1.5668 | Train Comb 2.4226 | Val Winner 0.9385 | Val Action 1.4408 | Val Comb 2.3060 | LR 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-397: 100%|██████████| 8/8 [02:05<00:00, 15.73s/it]\n",
      "val-epoch-397: 100%|██████████| 1/1 [00:11<00:00, 11.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397 | Train Winner 0.9742 | Train Action 1.5680 | Train Comb 2.4237 | Val Winner 0.9456 | Val Action 1.4367 | Val Comb 2.3107 | LR 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-398: 100%|██████████| 8/8 [02:05<00:00, 15.73s/it]\n",
      "val-epoch-398: 100%|██████████| 1/1 [00:11<00:00, 11.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398 | Train Winner 0.9769 | Train Action 1.5663 | Train Comb 2.4253 | Val Winner 0.9394 | Val Action 1.4422 | Val Comb 2.3078 | LR 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-399: 100%|██████████| 8/8 [02:06<00:00, 15.76s/it]\n",
      "val-epoch-399: 100%|██████████| 1/1 [00:11<00:00, 11.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399 | Train Winner 0.9736 | Train Action 1.5691 | Train Comb 2.4237 | Val Winner 0.9437 | Val Action 1.4416 | Val Comb 2.3119 | LR 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-400: 100%|██████████| 8/8 [02:06<00:00, 15.77s/it]\n",
      "val-epoch-400: 100%|██████████| 1/1 [00:11<00:00, 11.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400 | Train Winner 0.9739 | Train Action 1.5680 | Train Comb 2.4234 | Val Winner 0.9398 | Val Action 1.4354 | Val Comb 2.3039 | LR 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-401: 100%|██████████| 8/8 [02:05<00:00, 15.75s/it]\n",
      "val-epoch-401: 100%|██████████| 1/1 [00:11<00:00, 11.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401 | Train Winner 0.9757 | Train Action 1.5667 | Train Comb 2.4244 | Val Winner 0.9449 | Val Action 1.4369 | Val Comb 2.3100 | LR 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-402: 100%|██████████| 8/8 [02:06<00:00, 15.79s/it]\n",
      "val-epoch-402: 100%|██████████| 1/1 [00:11<00:00, 11.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 402 | Train Winner 0.9778 | Train Action 1.5680 | Train Comb 2.4273 | Val Winner 0.9469 | Val Action 1.4346 | Val Comb 2.3106 | LR 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-403: 100%|██████████| 8/8 [02:05<00:00, 15.73s/it]\n",
      "val-epoch-403: 100%|██████████| 1/1 [00:11<00:00, 11.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 403 | Train Winner 0.9751 | Train Action 1.5658 | Train Comb 2.4232 | Val Winner 0.9440 | Val Action 1.4354 | Val Comb 2.3081 | LR 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-404: 100%|██████████| 8/8 [02:05<00:00, 15.75s/it]\n",
      "val-epoch-404: 100%|██████████| 1/1 [00:11<00:00, 11.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 404 | Train Winner 0.9754 | Train Action 1.5661 | Train Comb 2.4237 | Val Winner 0.9424 | Val Action 1.4359 | Val Comb 2.3069 | LR 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-405: 100%|██████████| 8/8 [02:06<00:00, 15.77s/it]\n",
      "val-epoch-405: 100%|██████████| 1/1 [00:11<00:00, 11.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 405 | Train Winner 0.9751 | Train Action 1.5686 | Train Comb 2.4249 | Val Winner 0.9398 | Val Action 1.4303 | Val Comb 2.3007 | LR 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-406: 100%|██████████| 8/8 [02:06<00:00, 15.79s/it]\n",
      "val-epoch-406: 100%|██████████| 1/1 [00:11<00:00, 11.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 406 | Train Winner 0.9744 | Train Action 1.5688 | Train Comb 2.4244 | Val Winner 0.9443 | Val Action 1.4391 | Val Comb 2.3109 | LR 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-407: 100%|██████████| 8/8 [02:06<00:00, 15.81s/it]\n",
      "val-epoch-407: 100%|██████████| 1/1 [00:11<00:00, 11.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407 | Train Winner 0.9765 | Train Action 1.5643 | Train Comb 2.4237 | Val Winner 0.9510 | Val Action 1.4355 | Val Comb 2.3154 | LR 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-408: 100%|██████████| 8/8 [02:06<00:00, 15.85s/it]\n",
      "val-epoch-408: 100%|██████████| 1/1 [00:11<00:00, 11.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 408 | Train Winner 0.9744 | Train Action 1.5680 | Train Comb 2.4238 | Val Winner 0.9425 | Val Action 1.4370 | Val Comb 2.3076 | LR 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-409: 100%|██████████| 8/8 [02:06<00:00, 15.84s/it]\n",
      "val-epoch-409: 100%|██████████| 1/1 [00:11<00:00, 11.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 409 | Train Winner 0.9775 | Train Action 1.5652 | Train Comb 2.4253 | Val Winner 0.9442 | Val Action 1.4375 | Val Comb 2.3097 | LR 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-410: 100%|██████████| 8/8 [02:06<00:00, 15.86s/it]\n",
      "val-epoch-410: 100%|██████████| 1/1 [00:11<00:00, 11.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 410 | Train Winner 0.9760 | Train Action 1.5683 | Train Comb 2.4257 | Val Winner 0.9415 | Val Action 1.4301 | Val Comb 2.3022 | LR 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-411: 100%|██████████| 8/8 [02:14<00:00, 16.80s/it]\n",
      "val-epoch-411: 100%|██████████| 1/1 [00:12<00:00, 12.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 411 | Train Winner 0.9759 | Train Action 1.5673 | Train Comb 2.4250 | Val Winner 0.9400 | Val Action 1.4353 | Val Comb 2.3039 | LR 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-412: 100%|██████████| 8/8 [02:13<00:00, 16.64s/it]\n",
      "val-epoch-412: 100%|██████████| 1/1 [00:11<00:00, 11.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 412 | Train Winner 0.9750 | Train Action 1.5674 | Train Comb 2.4241 | Val Winner 0.9378 | Val Action 1.4300 | Val Comb 2.2983 | LR 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-413: 100%|██████████| 8/8 [02:18<00:00, 17.36s/it]\n",
      "val-epoch-413: 100%|██████████| 1/1 [00:13<00:00, 13.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 413 | Train Winner 0.9769 | Train Action 1.5657 | Train Comb 2.4249 | Val Winner 0.9383 | Val Action 1.4379 | Val Comb 2.3039 | LR 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-414: 100%|██████████| 8/8 [02:23<00:00, 17.98s/it]\n",
      "val-epoch-414: 100%|██████████| 1/1 [00:13<00:00, 13.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 414 | Train Winner 0.9759 | Train Action 1.5658 | Train Comb 2.4240 | Val Winner 0.9397 | Val Action 1.4343 | Val Comb 2.3030 | LR 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-415: 100%|██████████| 8/8 [02:26<00:00, 18.26s/it]\n",
      "val-epoch-415: 100%|██████████| 1/1 [00:13<00:00, 13.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415 | Train Winner 0.9743 | Train Action 1.5663 | Train Comb 2.4227 | Val Winner 0.9411 | Val Action 1.4364 | Val Comb 2.3058 | LR 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-416: 100%|██████████| 8/8 [02:27<00:00, 18.44s/it]\n",
      "val-epoch-416: 100%|██████████| 1/1 [00:13<00:00, 13.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 416 | Train Winner 0.9748 | Train Action 1.5704 | Train Comb 2.4258 | Val Winner 0.9426 | Val Action 1.4363 | Val Comb 2.3073 | LR 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-417: 100%|██████████| 8/8 [02:28<00:00, 18.55s/it]\n",
      "val-epoch-417: 100%|██████████| 1/1 [00:14<00:00, 14.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 417 | Train Winner 0.9753 | Train Action 1.5682 | Train Comb 2.4250 | Val Winner 0.9345 | Val Action 1.4321 | Val Comb 2.2962 | LR 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-epoch-418:   0%|          | 0/8 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m model_optimizer.zero_grad()\n\u001b[32m     16\u001b[39m combined_criterion_optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m winner_loss, action_loss, combined_loss = \u001b[43mprocess_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstateflow_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Check for NaN or Inf values in loss\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.isnan(combined_loss) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(combined_loss):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mprocess_batch\u001b[39m\u001b[34m(stateflow_model, batch)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess_batch\u001b[39m(stateflow_model, batch):\n\u001b[32m      2\u001b[39m     batch = move_to_device(batch, device)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     model_out = \u001b[43mstateflow_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mextract_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     winner_output, winner_target = \\\n\u001b[32m      6\u001b[39m         extract_winners_output_target(batch, model_out)\n\u001b[32m      7\u001b[39m     action_output, action_target = \\\n\u001b[32m      8\u001b[39m         extract_action_output_target(batch, model_out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programming/dicewar_learning/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programming/dicewar_learning/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programming/dicewar_learning/learning/model/stateflow.py:103\u001b[39m, in \u001b[36mDWStateFlowModel.forward\u001b[39m\u001b[34m(self, in_states, edges, node_graph_ids, edges_graph_ids)\u001b[39m\n\u001b[32m    101\u001b[39m     edge_mask = edges_graph_ids[active_edges_mask] == i_graph\n\u001b[32m    102\u001b[39m     \u001b[38;5;66;03m# node_mask = node_graph_ids == i_graph\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     graph_out_vals.append(\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwinner_logit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwinner_logit\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi_graph\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m        \u001b[49m\u001b[43medges_attack_logit\u001b[49m\u001b[43m=\u001b[49m\u001b[43medges_attack_logit\u001b[49m\u001b[43m[\u001b[49m\u001b[43medge_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[43mend_turn_logit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mend_turn_logit\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi_graph\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m graph_out_vals\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for i_epoch in range(start_epoch, n_epochs):\n",
    "    t_start = time.time()\n",
    "    \n",
    "    # Set model to training mode\n",
    "    stateflow_model.train()\n",
    "    \n",
    "    # Training phase with gradient tracking and parameter updates\n",
    "    train_winner_sum = torch.tensor(0.0, device=device)\n",
    "    train_action_sum = torch.tensor(0.0, device=device)\n",
    "    train_combined_sum = torch.tensor(0.0, device=device)\n",
    "    train_batches = 0\n",
    "    \n",
    "    for tb in tqdm.tqdm(train_loader, desc=f\"train-epoch-{i_epoch}\"):\n",
    "        # Zero the gradients\n",
    "        model_optimizer.zero_grad()\n",
    "        combined_criterion_optimizer.zero_grad()\n",
    "        \n",
    "        winner_loss, action_loss, combined_loss = process_batch(stateflow_model, tb)\n",
    "        \n",
    "        # Check for NaN or Inf values in loss\n",
    "        if torch.isnan(combined_loss) or torch.isinf(combined_loss):\n",
    "            raise ValueError(f\"Combined loss contains NaN or Inf values\")\n",
    "            \n",
    "        # Backward pass and optimize\n",
    "        combined_loss.backward()\n",
    "        model_optimizer.step()\n",
    "        combined_criterion_optimizer.step()\n",
    "\n",
    "        train_winner_sum += winner_loss.detach()\n",
    "        train_action_sum += action_loss.detach()\n",
    "        train_combined_sum += combined_loss.detach()\n",
    "        train_batches += 1\n",
    "        \n",
    "        if (time.time() - t_start) > time_limit: \n",
    "            print(f\"Stopping training after >{time_limit} seconds.\")\n",
    "            break\n",
    "            \n",
    "    train_winner_loss = train_winner_sum.item() / train_batches\n",
    "    train_action_loss = train_action_sum.item() / train_batches\n",
    "    train_combined_loss = train_combined_sum.item() / train_batches\n",
    "    t_train_done = time.time()\n",
    "\n",
    "    # Set model to evaluation mode for validation\n",
    "    stateflow_model.eval()\n",
    "    with torch.no_grad():\n",
    "        # avg loss on validation set\n",
    "        val_winner_sum = torch.tensor(0.0, device=device)\n",
    "        val_action_sum = torch.tensor(0.0, device=device)\n",
    "        val_combined_sum = torch.tensor(0.0, device=device)\n",
    "        val_batches = 0\n",
    "        \n",
    "        for vb in tqdm.tqdm(val_loader, desc=f\"val-epoch-{i_epoch}\"):\n",
    "            v_winner_loss, v_action_loss, v_combined_loss = process_batch(stateflow_model, vb)\n",
    "            \n",
    "            val_winner_sum += v_winner_loss\n",
    "            val_action_sum += v_action_loss\n",
    "            val_combined_sum += v_combined_loss\n",
    "            val_batches += 1\n",
    "            \n",
    "            if (time.time() - t_train_done) > time_limit / 5:\n",
    "                print(f\"Stopping validation after >{time_limit / 5} seconds.\")\n",
    "                break\n",
    "                \n",
    "        val_winner_loss = val_winner_sum.item() / val_batches\n",
    "        val_action_loss = val_action_sum.item() / val_batches\n",
    "        val_combined_loss = val_combined_sum.item() / val_batches\n",
    "        t_val_done = time.time()\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    checkpoint_path = os.path.join(models_dir, f\"{model_name}_{i_epoch}.pt\")\n",
    "    torch.save(\n",
    "        {\n",
    "            \"model_state\": stateflow_model.state_dict(),\n",
    "            \"combined_criterion_state\": combined_criterion.state_dict(),\n",
    "            \"scheduler_state\": scheduler.state_dict(),\n",
    "            \"epoch\": i_epoch\n",
    "        },\n",
    "        checkpoint_path\n",
    "    )\n",
    "\n",
    "    # times\n",
    "    train_time = t_train_done - t_start\n",
    "    val_time   = t_val_done - t_train_done\n",
    "    total_time = t_val_done - t_start\n",
    "\n",
    "    csv_writer.writerow([\n",
    "        i_epoch,\n",
    "        train_winner_loss,\n",
    "        train_action_loss,\n",
    "        train_combined_loss,\n",
    "        val_winner_loss,\n",
    "        val_action_loss,\n",
    "        val_combined_loss,\n",
    "        train_time,\n",
    "        val_time,\n",
    "        total_time,\n",
    "        combined_criterion.winner_err_log_scale.item(),\n",
    "        combined_criterion.action_err_log_scale.item()\n",
    "    ])\n",
    "    csv_file.flush()\n",
    "    \n",
    "    print(\n",
    "        f\"Epoch {i_epoch} | \"\n",
    "        f\"Train Winner {train_winner_loss:.4f} | \"\n",
    "        f\"Train Action {train_action_loss:.4f} | \"\n",
    "        f\"Train Comb {train_combined_loss:.4f} | \"\n",
    "        f\"Val Winner {val_winner_loss:.4f} | \"\n",
    "        f\"Val Action {val_action_loss:.4f} | \"\n",
    "        f\"Val Comb {val_combined_loss:.4f} | \"\n",
    "        f\"LR {scheduler.get_last_lr()[0]:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e71dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler.get_last_lr()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "de8b66e0",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "train-epoch-0:   9%|▉         | 20/218 [10:20<1:42:26, 31.04s/it]\n",
    "train-epoch-32: 100%|██████████| 8/8 [02:14<00:00, 16.86s/it]\n",
    "train-epoch-233: 100%|██████████| 8/8 [02:30<00:00, 18.78s/it]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036332dc",
   "metadata": {},
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a2f638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
