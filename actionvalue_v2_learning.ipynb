{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b276a13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib ipympl\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import tqdm\n",
    "import time\n",
    "import csv\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, ConcatDataset, random_split\n",
    "\n",
    "from learning.data.process_utils import move_to_device\n",
    "from learning.data.av2_utils import extract_input, collate_av2_data\n",
    "from learning.data.av2_utils import extract_output_target\n",
    "from learning.data.av2_dataset import ActionValueV2Dataset\n",
    "from learning.model.actionvalue_v2 import ActionValueModelV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2955fd39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cb39e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a fixed seed for reproducibility\n",
    "seed = 21\n",
    "torch.manual_seed(seed)\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "\n",
    "history_folder = \"server/history/\"\n",
    "history_files = sorted(glob.glob(os.path.join(history_folder, \"history_*.json\")))\n",
    "\n",
    "datasets = [ActionValueV2Dataset(f) for f in history_files]\n",
    "concatenated_dataset = ConcatDataset(datasets)\n",
    "\n",
    "train_ds, val_ds, test_ds = random_split(\n",
    "    concatenated_dataset,\n",
    "    [0.8, 0.1, 0.1],\n",
    "    generator=generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43efe07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ds 578341\n",
      "val_ds 72292\n",
      "test_ds 72292\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_ds, 10000, pin_memory=True, shuffle=True, \n",
    "                         collate_fn=collate_av2_data, generator=generator)\n",
    "val_loader = DataLoader(val_ds, 20000, pin_memory=True, shuffle=True, \n",
    "                       collate_fn=collate_av2_data, generator=generator)\n",
    "\n",
    "print(\"train_ds\", len(train_ds))\n",
    "print(\"val_ds\", len(val_ds))\n",
    "print(\"test_ds\", len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da9e03af",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e1a9fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a966078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading latest checkpoint: learning/actionvalue_v2_no_freeze_checkpoints/actionvalue_v2_no_freeze_000164.pt (epoch 164)\n"
     ]
    }
   ],
   "source": [
    "model_state = None\n",
    "optim_state = None\n",
    "latest_epoch = -1\n",
    "\n",
    "freeze = False\n",
    "\n",
    "model_name = \"actionvalue_v2\" + (\"_no_freeze\" if not freeze else \"\")\n",
    "models_dir = f\"learning/{model_name}_checkpoints\" \n",
    "\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Find the latest checkpoint file (with highest epoch number)\n",
    "checkpoint_files = glob.glob(os.path.join(models_dir, f\"{model_name}_*.pt\"))\n",
    "if checkpoint_files:\n",
    "    # Extract epoch numbers from filenames\n",
    "    epoch_nums = [int(f.split(\"_\")[-1].split(\".\")[0]) for f in checkpoint_files]\n",
    "    latest_epoch = max(epoch_nums)\n",
    "    latest_checkpoint = os.path.join(models_dir, f\"{model_name}_{latest_epoch:06}.pt\")\n",
    "    print(f\"Loading latest checkpoint: {latest_checkpoint} (epoch {latest_epoch})\")\n",
    "    checkpoint = torch.load(latest_checkpoint, map_location=torch.device('cpu'))\n",
    "    model_state = checkpoint[\"model_state\"]\n",
    "    optim_state = checkpoint[\"optim_state\"]\n",
    "else:\n",
    "    print(\"No valid checkpoint files found\")\n",
    "    \n",
    "start_epoch = latest_epoch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5463a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "action_value_model = ActionValueModelV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10e1dfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_from_old_model = (model_state is None)\n",
    "\n",
    "if init_from_old_model:\n",
    "    print(\"⚠️⚠️⚠️ Warning, model is being initialized from an old checkpoint\")\n",
    "    \n",
    "    checkpoint = torch.load(\n",
    "        \"learning/old_models/nodevalue_full.pt\",\n",
    "        map_location=torch.device('cpu')\n",
    "    )\n",
    "    model_state = checkpoint[\"model_state\"]\n",
    "\n",
    "    # update old model state to match the new one\n",
    "    mismatch = action_value_model.load_state_dict(model_state, strict=False)\n",
    "    model_state = action_value_model.state_dict()\n",
    "\n",
    "    missing_keys, unexpected_keys = mismatch\n",
    "\n",
    "    for mk in missing_keys:\n",
    "        print(\"missing key\", mk)\n",
    "\n",
    "    for uk in unexpected_keys:\n",
    "        print(\"unexpected key\", uk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de5de2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state loaded from checkpoint.\n",
      "Model created. Total parameters: 8,363\n",
      "Trainable parameters: 4,365 (52.19%)\n",
      "Frozen parameters: 3,998\n",
      "Only attack_value_fn and end_turn_value_fn modules are trainable.\n"
     ]
    }
   ],
   "source": [
    "# Load the model state if available\n",
    "if model_state is not None:\n",
    "    action_value_model.load_state_dict(model_state)\n",
    "    print(f\"Model state loaded from checkpoint.\")\n",
    "\n",
    "if freeze:\n",
    "    # Only make attack_value_fn and end_turn_value_fn parameters trainable\n",
    "    for name, param in action_value_model.named_parameters():\n",
    "        if name.startswith('attack_value_fn') or name.startswith('end_turn_value_fn'):\n",
    "            param.requires_grad = True\n",
    "        else:\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        \n",
    "trainable_params = sum(p.numel() for p in action_value_model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in action_value_model.parameters())\n",
    "print(f\"Model created. Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,} ({trainable_params/total_params*100:.2f}%)\")\n",
    "print(f\"Frozen parameters: {total_params - trainable_params:,}\")\n",
    "print(\"Only attack_value_fn and end_turn_value_fn modules are trainable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d5403d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed parameter trainable status:\n",
      "✗ FROZEN: in_states_mean, shape=torch.Size([19])\n",
      "✗ FROZEN: in_states_std, shape=torch.Size([19])\n",
      "✓ TRAINABLE: gat_layers.0.passthrough_coef, shape=torch.Size([])\n",
      "✓ TRAINABLE: gat_layers.0.message_heads.0.transform_fn.weight, shape=torch.Size([20, 19])\n",
      "✓ TRAINABLE: gat_layers.0.message_heads.1.transform_fn.weight, shape=torch.Size([20, 19])\n",
      "✓ TRAINABLE: gat_layers.0.attention_coef_heads.0.transform_fn.weight, shape=torch.Size([1, 40])\n",
      "✓ TRAINABLE: gat_layers.0.attention_coef_heads.1.transform_fn.weight, shape=torch.Size([1, 40])\n",
      "✗ FROZEN: gat_layers.0.in_states_pass.weight, shape=torch.Size([40, 19])\n",
      "✓ TRAINABLE: gat_layers.1.passthrough_coef, shape=torch.Size([])\n",
      "✓ TRAINABLE: gat_layers.1.message_heads.0.transform_fn.weight, shape=torch.Size([20, 40])\n",
      "✓ TRAINABLE: gat_layers.1.message_heads.1.transform_fn.weight, shape=torch.Size([20, 40])\n",
      "✓ TRAINABLE: gat_layers.1.attention_coef_heads.0.transform_fn.weight, shape=torch.Size([1, 40])\n",
      "✓ TRAINABLE: gat_layers.1.attention_coef_heads.1.transform_fn.weight, shape=torch.Size([1, 40])\n",
      "✗ FROZEN: gat_layers.1.in_states_pass.weight, shape=torch.Size([40, 40])\n",
      "✓ TRAINABLE: gat_layers.2.passthrough_coef, shape=torch.Size([])\n",
      "✓ TRAINABLE: gat_layers.2.message_heads.0.transform_fn.weight, shape=torch.Size([20, 40])\n",
      "✓ TRAINABLE: gat_layers.2.message_heads.1.transform_fn.weight, shape=torch.Size([20, 40])\n",
      "✓ TRAINABLE: gat_layers.2.attention_coef_heads.0.transform_fn.weight, shape=torch.Size([1, 40])\n",
      "✓ TRAINABLE: gat_layers.2.attention_coef_heads.1.transform_fn.weight, shape=torch.Size([1, 40])\n",
      "✗ FROZEN: gat_layers.2.in_states_pass.weight, shape=torch.Size([40, 40])\n",
      "✓ TRAINABLE: attack_value_fn.edge_value_fn.weight, shape=torch.Size([1, 80])\n",
      "✓ TRAINABLE: attack_value_fn.edge_value_fn.bias, shape=torch.Size([1])\n",
      "✓ TRAINABLE: end_turn_value_fn.attention_coef_fn.transform_fn.weight, shape=torch.Size([1, 40])\n",
      "✓ TRAINABLE: end_turn_value_fn.summary_fn.weight, shape=torch.Size([1, 40])\n",
      "✓ TRAINABLE: end_turn_value_fn.summary_fn.bias, shape=torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# Print details about which specific parameters are trainable\n",
    "print(\"Detailed parameter trainable status:\")\n",
    "for name, param in action_value_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"✓ TRAINABLE: {name}, shape={param.shape}\")\n",
    "    else:\n",
    "        # For frozen parameters, just count by module\n",
    "        module = name.split('.')[0]\n",
    "        print(f\"✗ FROZEN: {name}, shape={param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f25026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b8afa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── CSV set‑up: log one row per epoch ───────────────────────────────────────\n",
    "csv_path = f\"{model_name}_epoch_metrics.csv\"\n",
    "epoch_log_file_exists = os.path.isfile(csv_path)\n",
    "if epoch_log_file_exists and os.path.getsize(csv_path) == 0:\n",
    "    os.remove(csv_path)\n",
    "    epoch_log_file_exists = False\n",
    "\n",
    "csv_file = open(csv_path, \"a\", newline=\"\")  # Open in append mode\n",
    "csv_writer = csv.writer(csv_file)\n",
    "\n",
    "# Only write header if file doesn't exist yet\n",
    "if not epoch_log_file_exists:\n",
    "    csv_writer.writerow([\n",
    "        \"epoch\",           # 0‑based epoch index\n",
    "        \"train_loss\",      # average training loss for the epoch\n",
    "        \"val_loss\",        # average validation loss for the epoch\n",
    "        \"train_time_sec\",  # seconds spent in training phase\n",
    "        \"val_time_sec\",    # seconds spent in validation phase\n",
    "        \"total_time_sec\"   # train + val\n",
    "    ])\n",
    "\n",
    "# ── model / optimizer prep ─────────────────────────────────────────────────\n",
    "\n",
    "n_epochs   = 10000\n",
    "device     = torch.device(\"cuda\", 0)\n",
    "train_time_limit = 100 * 60\n",
    "val_time_limit = train_time_limit / 5\n",
    "criterion  = nn.MSELoss()\n",
    "\n",
    "action_value_model = action_value_model.to(device)\n",
    "\n",
    "optimizer  = torch.optim.Adam(\n",
    "    [p for p in action_value_model.parameters() if p.requires_grad],\n",
    "    lr=1e-3\n",
    ")\n",
    "reset_optimizer = True\n",
    "if not reset_optimizer and optim_state is not None:\n",
    "    optimizer.load_state_dict(optim_state)\n",
    "\n",
    "scheduler  = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\",\n",
    "    factor=0.25,\n",
    "    patience=10,\n",
    "    threshold=0.0001,\n",
    "    min_lr=1e-8\n",
    ")\n",
    "\n",
    "mean_val = action_value_model.mean_val\n",
    "std_val = action_value_model.std_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea054f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── INITIAL (untrained) LOSS EVALUATION ───────────────────────────────────────\n",
    "if not epoch_log_file_exists:\n",
    "    action_value_model.eval()\n",
    "    with torch.no_grad():\n",
    "        t_start = time.time()\n",
    "\n",
    "        # avg loss on training set *without* gradient tracking\n",
    "        init_train_sum, init_train_batches = 0.0, 0\n",
    "        for b in tqdm.tqdm(train_loader, desc=\"init‑train\"):\n",
    "            b = move_to_device(b, device)\n",
    "            out = action_value_model(*extract_input(b))\n",
    "            o, t = extract_output_target(b, out, mean_val, std_val)\n",
    "            init_train_sum += criterion(o, t).item()\n",
    "            init_train_batches += 1\n",
    "            if (time.time() - t_start) > train_time_limit: \n",
    "                print(f\"Stopping training after >{train_time_limit} seconds.\")\n",
    "                break\n",
    "        init_train_loss = init_train_sum / init_train_batches\n",
    "        t_train_done = time.time()\n",
    "\n",
    "        # avg loss on validation set\n",
    "        init_val_sum, init_val_batches = 0.0, 0\n",
    "        for vb in tqdm.tqdm(val_loader, desc=\"init‑val\"):\n",
    "            vb = move_to_device(vb, device)\n",
    "            vout = action_value_model(*extract_input(vb))\n",
    "            vo, vt = extract_output_target(\n",
    "                vb, vout, mean_val, std_val\n",
    "            )\n",
    "            init_val_sum += criterion(vo, vt).item()\n",
    "            init_val_batches += 1\n",
    "            if (time.time() - t_train_done) > val_time_limit:\n",
    "                print(f\"Stopping validation after >{val_time_limit} seconds.\")\n",
    "                break\n",
    "        init_val_loss = init_val_sum / init_val_batches\n",
    "        t_val_done = time.time()\n",
    "\n",
    "    # times\n",
    "    init_train_time = t_train_done - t_start\n",
    "    init_val_time   = t_val_done - t_train_done\n",
    "    init_total_time = t_val_done - t_start\n",
    "\n",
    "    # write initial row (epoch = None)\n",
    "    csv_writer.writerow([\n",
    "        -1,\n",
    "        init_train_loss,\n",
    "        init_val_loss,\n",
    "        init_train_time,\n",
    "        init_val_time,\n",
    "        init_total_time\n",
    "    ])\n",
    "    csv_file.flush()\n",
    "    print(\n",
    "        f\"Initial (-1) | \"\n",
    "        f\"Train {init_train_loss:.4f} | \"\n",
    "        f\"Val {init_val_loss:.4f} | \"\n",
    "        f\"Time {init_total_time:.1f}s (T {init_train_time:.1f}s | \"\n",
    "        f\"V {init_val_time:.1f}s)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b88b91e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.001]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.get_last_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1f88112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 165:   0%|          | 0/58 [00:00<?, ?it/s]/home/maxim/Programming/dicewar_learning/learning/model/utils.py:39: UserWarning: index_reduce() is in beta and the API may change at any time. (Triggered internally at /pytorch/aten/src/ATen/native/cuda/Indexing.cu:1432.)\n",
      "  max_per_index.index_reduce_(\n",
      "train 165:  52%|█████▏    | 30/58 [10:15<09:34, 20.51s/it, av_loss=0.753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping training after >600 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val 165: 100%|██████████| 4/4 [01:52<00:00, 28.22s/it, av_loss=0.697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165 | Train 0.7530 | Val 0.6975 | LR 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 166:  53%|█████▎    | 31/58 [10:16<08:56, 19.87s/it, av_loss=0.752]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping training after >600 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val 166:  75%|███████▌  | 3/4 [02:00<00:40, 40.21s/it, av_loss=0.694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping validation after >120.0 seconds.\n",
      "Epoch 166 | Train 0.7516 | Val 0.6935 | LR 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 167:  55%|█████▌    | 32/58 [10:05<08:12, 18.93s/it, av_loss=0.752]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping training after >600 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val 167: 100%|██████████| 4/4 [01:55<00:00, 28.88s/it, av_loss=0.697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167 | Train 0.7525 | Val 0.6971 | LR 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 168:  55%|█████▌    | 32/58 [10:18<08:22, 19.32s/it, av_loss=0.753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping training after >600 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val 168: 100%|██████████| 4/4 [01:51<00:00, 27.79s/it, av_loss=0.696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168 | Train 0.7533 | Val 0.6960 | LR 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 169:  53%|█████▎    | 31/58 [10:10<08:51, 19.69s/it, av_loss=0.775]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping training after >600 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val 169: 100%|██████████| 4/4 [01:52<00:00, 28.06s/it, av_loss=0.695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169 | Train 0.7752 | Val 0.6946 | LR 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 170:  17%|█▋        | 10/58 [03:27<16:33, 20.70s/it, av_loss=0.755]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m outputs, targets = extract_output_target(t_batch, model_out, mean_val, std_val)\n\u001b[32m     20\u001b[39m loss = criterion(outputs, targets)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m optimizer.step()\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.isnan(loss) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(loss):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programming/dicewar_learning/venv/lib/python3.12/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programming/dicewar_learning/venv/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programming/dicewar_learning/venv/lib/python3.12/site-packages/torch/autograd/graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, n_epochs):\n",
    "    t_start = time.time()\n",
    "\n",
    "    # ── TRAINING -----------------------------------------------------------\n",
    "    action_value_model.train()\n",
    "    sum_train_loss = torch.tensor(0.0, device=device)\n",
    "    n_train_batches = 0\n",
    "\n",
    "    t_batch_tqdm = tqdm.tqdm(\n",
    "        train_loader, \n",
    "        desc=f\"train {epoch}\" \n",
    "    )\n",
    "    for t_batch in t_batch_tqdm:\n",
    "        t_batch = move_to_device(t_batch, device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        model_out = action_value_model(*extract_input(t_batch))\n",
    "        outputs, targets = extract_output_target(t_batch, model_out, mean_val, std_val)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if torch.isnan(loss) or torch.isinf(loss):\n",
    "            raise ValueError(f\"Loss contains NaN or Inf values\")\n",
    "        \n",
    "        sum_train_loss += loss.detach()\n",
    "        n_train_batches += 1\n",
    "        t_batch_tqdm.set_postfix(av_loss=sum_train_loss.item()/n_train_batches)\n",
    "        if (time.time() - t_start) > train_time_limit: \n",
    "            print(f\"Stopping training after >{train_time_limit} seconds.\")\n",
    "            break\n",
    "        \n",
    "    t_batch_tqdm.close()\n",
    "\n",
    "    avg_train_loss = sum_train_loss.item() / n_train_batches\n",
    "    t_train_done = time.time()\n",
    "\n",
    "    # ── VALIDATION ---------------------------------------------------------\n",
    "    action_value_model.eval()\n",
    "    sum_val_loss = 0.0\n",
    "    n_val_batches = 0\n",
    "    with torch.no_grad():\n",
    "        v_batch_tqdm = tqdm.tqdm(\n",
    "            val_loader, \n",
    "            desc=f\"val {epoch}\" \n",
    "        )\n",
    "        for v_batch in v_batch_tqdm:\n",
    "            v_batch = move_to_device(v_batch, device)\n",
    "\n",
    "            v_out = action_value_model(*extract_input(v_batch))\n",
    "            v_outputs, v_targets = extract_output_target(v_batch, v_out, mean_val, std_val)\n",
    "            val_loss = criterion(v_outputs, v_targets)\n",
    "\n",
    "            if torch.isnan(val_loss) or torch.isinf(val_loss):\n",
    "                raise ValueError(f\"Loss contains NaN or Inf values\")\n",
    "            \n",
    "            sum_val_loss += val_loss\n",
    "            n_val_batches += 1\n",
    "            v_batch_tqdm.set_postfix(av_loss=sum_val_loss.item()/n_val_batches)\n",
    "            if (time.time() - t_train_done) > val_time_limit:\n",
    "                print(f\"Stopping validation after >{val_time_limit} seconds.\")\n",
    "                break\n",
    "\n",
    "        v_batch_tqdm.close()\n",
    "\n",
    "    avg_val_loss = sum_val_loss.item() / n_val_batches\n",
    "    t_val_done = time.time()\n",
    "\n",
    "    # Step the learning rate scheduler after each epoch\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # ── CSV logging ---------------------------------------------------------\n",
    "    train_time = t_train_done - t_start\n",
    "    val_time   = t_val_done   - t_train_done\n",
    "    total_time = t_val_done   - t_start\n",
    "\n",
    "\n",
    "    checkpoint_data = {\n",
    "        \"epoch\": epoch,\n",
    "        \"optim_state\": optimizer.state_dict(),\n",
    "        \"model_state\": action_value_model.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint_data, os.path.join(models_dir, f\"{model_name}_{epoch:06}.pt\"))\n",
    "    \n",
    "    csv_writer.writerow([\n",
    "        epoch,\n",
    "        avg_train_loss,\n",
    "        avg_val_loss,\n",
    "        train_time,\n",
    "        val_time,\n",
    "        total_time\n",
    "    ])\n",
    "    csv_file.flush()  # ensure data is written even if run aborts\n",
    "\n",
    "    # ── console printout ----------------------------------------------------\n",
    "    print(\n",
    "        f\"Epoch {epoch} | \"\n",
    "        f\"Train {avg_train_loss:.4f} | \"\n",
    "        f\"Val {avg_val_loss:.4f} | \"\n",
    "        f\"LR {scheduler.get_last_lr()[0]}\"\n",
    "    )\n",
    "# ── tidy‑up ----------------------------------------------------------------\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bca4bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcf5745",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47f5b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
